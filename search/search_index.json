{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>Welcome to my site.</p> <p>You will find various articles here on technical subjects which interest me. Most of these articles were written by AI agents in the course of conversations had with me. The conversations are grouped together as project folders in the left sidebar. </p> <p>I use Obsidian to organise and view that material locally and git to manage version control and distribution. </p> <p>Content is created by AI in Markdown, converted into html by Material for MKDocs and published to GitHub Pages. </p> <p>Diagrams are generated using Mermaid embedded markdown. </p> <pre><code>flowchart TD\n  A[Markdown] --&gt; B[MkDocs build]\n  B --&gt; C[GitHub Pages]</code></pre>"},{"location":"Beckhoff_MCP/","title":"Startup Guide","text":"<p>An MCP (Model Context Protocol) server that provides read-only access to Beckhoff TwinCAT PLCs via ADS (Automation Device Specification).</p>"},{"location":"Beckhoff_MCP/#features","title":"Features","text":"<ul> <li>Query PLC device information and state</li> <li>List and search PLC symbols</li> <li>Read single or multiple PLC variables</li> <li>Dynamic PLC discovery and connection via UDP (port 48899)</li> <li>EtherCAT diagnostics - master state, slave count, topology, and slave info</li> <li>Custom ADS port access - query and read from any ADS port (e.g., I/O Image ports)</li> <li>Graceful startup - server starts even if no local PLC is connected</li> <li>Automatic ADS route creation</li> <li>Automatic symbol caching for fast lookups</li> <li>Support for common TwinCAT data types</li> </ul>"},{"location":"Beckhoff_MCP/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>Beckhoff TwinCAT runtime with ADS enabled</li> <li>ADS routing configured (for remote PLCs)</li> </ul>"},{"location":"Beckhoff_MCP/#installation","title":"Installation","text":"<pre><code># Clone or navigate to the project directory\ncd beckhoff_mcp\n\n# Install with pip\npip install -e .\n\n# Or install dependencies directly\npip install mcp pyads pydantic\n</code></pre>"},{"location":"Beckhoff_MCP/#uninstallation","title":"Uninstallation","text":"<p>To uninstall the current version before installing a new one:</p> <pre><code># Uninstall the package\npip uninstall beckhoff_mcp\n\n# Verify it's removed\npip show beckhoff_mcp\n</code></pre>"},{"location":"Beckhoff_MCP/#configuration","title":"Configuration","text":""},{"location":"Beckhoff_MCP/#default-connection-settings","title":"Default Connection Settings","text":"<p>The server attempts to connect to a local TwinCAT PLC on startup:</p> <pre><code>AMS_NET_ID = \"127.0.0.1.1.1\"  # Localhost AMS Net ID\nAMS_PORT = 851                 # TwinCAT 3 PLC Runtime 1\n</code></pre> <p>Note: If no local PLC is available (e.g., TwinCAT is not running or is in Config mode), the server will start in disconnected mode. You can then use <code>beckhoff_discover_and_connect</code> to connect to a remote PLC.</p> <p>To modify the default settings, edit <code>src/beckhoff_mcp/server.py</code> and update the constants at the top of the file.</p>"},{"location":"Beckhoff_MCP/#dynamic-connection-runtime","title":"Dynamic Connection (Runtime)","text":"<p>You can also connect to remote PLCs at runtime using the <code>beckhoff_discover_and_connect</code> tool. Simply ask Claude to connect to a specific IP address:</p> <pre><code>&lt;beckhoff:mcp: ip=192.168.1.54&gt;\n</code></pre> <p>Or with credentials for automatic route creation:</p> <pre><code>Connect to PLC at 192.168.1.54 with username admin and password secret\n</code></pre>"},{"location":"Beckhoff_MCP/#common-ams-port-numbers","title":"Common AMS Port Numbers","text":"Port Description 851 TwinCAT 3 PLC Runtime 1 852 TwinCAT 3 PLC Runtime 2 853 TwinCAT 3 PLC Runtime 3 854 TwinCAT 3 PLC Runtime 4"},{"location":"Beckhoff_MCP/#usage","title":"Usage","text":""},{"location":"Beckhoff_MCP/#running-the-server","title":"Running the Server","text":"<pre><code># Using the installed script\nbeckhoff_mcp\n\n# Or run directly\npython -m beckhoff_mcp.server\n</code></pre>"},{"location":"Beckhoff_MCP/#claude-desktop-configuration","title":"Claude Desktop Configuration","text":"<p>Add to your Claude Desktop config (<code>claude_desktop_config.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"beckhoff_mcp\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"beckhoff_mcp.server\"]\n    }\n  }\n}\n</code></pre> <p>Or if installed as a package:</p> <pre><code>{\n  \"mcpServers\": {\n    \"beckhoff_mcp\": {\n      \"command\": \"beckhoff_mcp\"\n    }\n  }\n}\n</code></pre>"},{"location":"Beckhoff_MCP/#available-tools","title":"Available Tools","text":""},{"location":"Beckhoff_MCP/#beckhoff_get_device_info","title":"<code>beckhoff_get_device_info</code>","text":"<p>Get PLC device name and version information.</p> <p>Input: None</p> <p>Output: <pre><code>{\n  \"device_name\": \"TwinCAT PLC\",\n  \"version\": {\n    \"major\": 3,\n    \"minor\": 1,\n    \"build\": 4024\n  }\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_get_device_state","title":"<code>beckhoff_get_device_state</code>","text":"<p>Get current ADS state and device state.</p> <p>Input: None</p> <p>Output: <pre><code>{\n  \"ads_state\": {\n    \"code\": 5,\n    \"name\": \"Run\"\n  },\n  \"device_state\": 0\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_list_symbols","title":"<code>beckhoff_list_symbols</code>","text":"<p>List available PLC symbols with optional filtering and pagination.</p> <p>Input: - <code>filter</code> (optional): Filter pattern with wildcards (e.g., <code>\"GVL_*\"</code>, <code>\"*Motor*\"</code>) - <code>limit</code> (optional, default 50): Maximum results to return - <code>offset</code> (optional, default 0): Pagination offset</p> <p>Output: <pre><code>{\n  \"symbols\": [\n    {\"name\": \"GVL.bStart\", \"type\": \"BOOL\", \"comment\": \"Start button\"},\n    {\"name\": \"GVL.nCounter\", \"type\": \"INT\", \"comment\": \"Cycle counter\"}\n  ],\n  \"pagination\": {\n    \"total\": 150,\n    \"offset\": 0,\n    \"limit\": 50,\n    \"returned\": 50,\n    \"has_more\": true,\n    \"next_offset\": 50\n  }\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_get_symbol_info","title":"<code>beckhoff_get_symbol_info</code>","text":"<p>Get detailed information about a specific symbol.</p> <p>Input: - <code>symbol_name</code> (required): Full symbol name (e.g., <code>\"MAIN.bStart\"</code>)</p> <p>Output: <pre><code>{\n  \"name\": \"MAIN.bStart\",\n  \"type\": \"BOOL\",\n  \"index_group\": 16448,\n  \"index_offset\": 0,\n  \"size\": 1,\n  \"comment\": \"Start button\"\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_read_variable","title":"<code>beckhoff_read_variable</code>","text":"<p>Read a single PLC variable by symbol name.</p> <p>Input: - <code>symbol_name</code> (required): Full variable name (e.g., <code>\"GVL.nCounter\"</code>)</p> <p>Output: <pre><code>{\n  \"name\": \"GVL.nCounter\",\n  \"type\": \"INT\",\n  \"value\": 42\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_read_variables","title":"<code>beckhoff_read_variables</code>","text":"<p>Read multiple PLC variables at once.</p> <p>Input: - <code>symbol_names</code> (required): List of variable names</p> <p>Output: <pre><code>{\n  \"results\": [\n    {\"name\": \"GVL.bStart\", \"type\": \"BOOL\", \"value\": true},\n    {\"name\": \"GVL.nCounter\", \"type\": \"INT\", \"value\": 42}\n  ],\n  \"errors\": null,\n  \"summary\": {\n    \"requested\": 2,\n    \"successful\": 2,\n    \"failed\": 0\n  }\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_discover_and_connect","title":"<code>beckhoff_discover_and_connect</code>","text":"<p>Discover and connect to a remote PLC by IP address using UDP discovery.</p> <p>Input: - <code>ip_address</code> (required): IP address of the target PLC - <code>username</code> (optional): PLC login for route creation - <code>password</code> (optional): PLC password for route creation - <code>ams_port</code> (optional, default 851): ADS port number - <code>route_name</code> (optional): Custom name for the route</p> <p>Output: <pre><code>{\n  \"success\": true,\n  \"ip_address\": \"192.168.1.54\",\n  \"discovered_ams_net_id\": \"192.168.1.54.1.1\",\n  \"ams_port\": 851,\n  \"route_added\": true,\n  \"device_info\": {\n    \"device_name\": \"CX-12345\",\n    \"version\": {\"version\": 3, \"revision\": 1, \"build\": 4024}\n  },\n  \"symbols_cached\": 150\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_connection_status","title":"<code>beckhoff_connection_status</code>","text":"<p>Get information about the current PLC connection.</p> <p>Input: None</p> <p>Output: <pre><code>{\n  \"ams_net_id\": \"192.168.1.54.1.1\",\n  \"ams_port\": 851,\n  \"ip_address\": \"192.168.1.54\",\n  \"is_remote\": true,\n  \"is_connected\": true,\n  \"symbols_cached\": 150\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#ethercat-diagnostic-tools","title":"EtherCAT Diagnostic Tools","text":""},{"location":"Beckhoff_MCP/#beckhoff_get_ethercat_master_state","title":"<code>beckhoff_get_ethercat_master_state</code>","text":"<p>Get the EtherCAT master state (Init, PreOp, SafeOp, Op).</p> <p>Input: None</p> <p>Output: <pre><code>{\n  \"master_state\": {\"code\": 8, \"name\": \"Op\"},\n  \"ams_net_id\": \"192.168.1.54.1.1\",\n  \"ethercat_port\": 65535\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_get_ethercat_slave_count","title":"<code>beckhoff_get_ethercat_slave_count</code>","text":"<p>Get the number of connected EtherCAT slaves.</p> <p>Input: None</p> <p>Output: <pre><code>{\n  \"slave_count\": 5,\n  \"ams_net_id\": \"192.168.1.54.1.1\"\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_get_ethercat_topology","title":"<code>beckhoff_get_ethercat_topology</code>","text":"<p>Get the full EtherCAT network topology with all slave information.</p> <p>Input: None</p> <p>Output: <pre><code>{\n  \"slave_count\": 3,\n  \"slaves\": [\n    {\"address\": 1, \"state\": {\"code\": 8, \"name\": \"Op\"}, \"vendor_id\": 2, \"product_code\": 100663346},\n    {\"address\": 2, \"state\": {\"code\": 8, \"name\": \"Op\"}, \"vendor_id\": 2, \"product_code\": 100728882}\n  ],\n  \"ams_net_id\": \"192.168.1.54.1.1\"\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_get_ethercat_slave_info","title":"<code>beckhoff_get_ethercat_slave_info</code>","text":"<p>Get detailed information about a specific EtherCAT slave.</p> <p>Input: - <code>slave_address</code> (required): The slave address (1-indexed)</p> <p>Output: <pre><code>{\n  \"address\": 1,\n  \"state\": {\"code\": 8, \"name\": \"Op\"},\n  \"vendor_id\": 2,\n  \"product_code\": 100663346,\n  \"crc_errors\": 0,\n  \"ams_net_id\": \"192.168.1.54.1.1\"\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#custom-ads-port-tools","title":"Custom ADS Port Tools","text":"<p>Some EtherCAT devices (like EK1200 EtherCAT Couplers) expose their I/O data on custom ADS ports rather than the standard EtherCAT master port (0xFFFF). Use these tools to access such devices.</p>"},{"location":"Beckhoff_MCP/#beckhoff_query_ads_port","title":"<code>beckhoff_query_ads_port</code>","text":"<p>Query a custom ADS port to discover available symbols and device information.</p> <p>Input: - <code>ads_port</code> (required): The ADS port number (e.g., 27905 or 0x6D01)</p> <p>Output: <pre><code>{\n  \"ads_port\": 27905,\n  \"ads_port_hex\": \"0x6D01\",\n  \"ams_net_id\": \"5.59.203.226.1.1\",\n  \"ip_address\": \"192.168.1.67\",\n  \"success\": true,\n  \"device_info\": {\n    \"device_name\": \"EK1200\",\n    \"version\": {\"version\": 3, \"revision\": 1, \"build\": 4024}\n  },\n  \"state\": {\n    \"ads_state\": {\"code\": 5, \"name\": \"Run\"},\n    \"device_state\": 0\n  },\n  \"symbol_count\": 4,\n  \"symbols_preview\": [\n    {\"name\": \"Inputs.EL1008.Channel 1.Input\", \"type\": \"BOOL\"},\n    {\"name\": \"Outputs.EL2008.Channel 1.Output\", \"type\": \"BOOL\"}\n  ]\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/#beckhoff_read_from_port","title":"<code>beckhoff_read_from_port</code>","text":"<p>Read a variable from a custom ADS port.</p> <p>Input: - <code>ads_port</code> (required): The ADS port number (e.g., 27905) - <code>symbol_name</code> (required): The symbol name to read</p> <p>Output: <pre><code>{\n  \"name\": \"Inputs.EL1008.Channel 1.Input\",\n  \"type\": \"BOOL\",\n  \"value\": true,\n  \"ads_port\": 27905\n}\n</code></pre></p> <p>How to find the ADS port: In TwinCAT XAE, double-click on the device (e.g., under I/O &gt; Devices &gt; EtherCAT), go to the \"ADS\" tab, and note the \"ADS Server Port\" value.</p>"},{"location":"Beckhoff_MCP/#supported-data-types","title":"Supported Data Types","text":"TwinCAT Type Description BOOL Boolean (TRUE/FALSE) BYTE 8-bit unsigned SINT 8-bit signed USINT 8-bit unsigned INT 16-bit signed UINT 16-bit unsigned DINT 32-bit signed UDINT 32-bit unsigned LINT 64-bit signed ULINT 64-bit unsigned REAL 32-bit float LREAL 64-bit float STRING Text string TIME, DATE, DT, TOD Time types (as UDINT) WORD, DWORD, LWORD Bit string types <p>Note: Complex types (arrays, structures) are not fully supported for reading. The server will return type information but may not be able to read the value directly.</p>"},{"location":"Beckhoff_MCP/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Beckhoff_MCP/#connection-errors","title":"Connection Errors","text":"<p>If you see connection errors:</p> <ol> <li>Verify TwinCAT is running: Check that TwinCAT System Service is running and the PLC is in Run mode</li> <li>Check AMS Net ID: Ensure the AMS Net ID in the server matches your system (run <code>hostname</code> in TwinCAT XAE to find it)</li> <li>Verify ADS routing: For remote connections, ensure ADS routes are configured on both systems</li> <li>Check firewall: ADS uses TCP port 48898 by default</li> </ol>"},{"location":"Beckhoff_MCP/#symbol-not-found","title":"Symbol Not Found","text":"<p>If symbols are not found:</p> <ol> <li>Ensure the PLC project is activated and running</li> <li>Check the exact symbol name including namespace (e.g., <code>MAIN.</code>, <code>GVL.</code>)</li> <li>Symbol names are case-sensitive</li> <li>Try <code>beckhoff_list_symbols</code> with a filter to find the correct name</li> </ol>"},{"location":"Beckhoff_MCP/#license","title":"License","text":"<p>MIT License</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/","title":"Beckhoff PLC MCP Server Documentation","text":""},{"location":"Beckhoff_MCP/DOCUMENTATION/#what-is-this","title":"What is this?","text":"<p>The Beckhoff PLC MCP Server is a Model Context Protocol (MCP) server that enables Claude (or other MCP-compatible AI assistants) to communicate directly with Beckhoff TwinCAT PLCs. It provides read-only access to PLC data, allowing you to query device information, browse symbols, and read variable values through natural language conversations.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#what-is-mcp","title":"What is MCP?","text":"<p>Model Context Protocol (MCP) is an open standard developed by Anthropic that allows AI assistants to securely connect to external data sources and tools. Think of it as a \"plugin system\" for AI assistants that enables them to:</p> <ul> <li>Access real-time data from external systems</li> <li>Execute specific operations through defined tools</li> <li>Maintain context across conversations</li> </ul> <p>MCP servers run locally on your machine and communicate with Claude Desktop via stdio (standard input/output), ensuring your data stays local and secure.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     stdio      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      ADS       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Claude Desktop \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  beckhoff_mcp   \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  TwinCAT    \u2502\n\u2502  (MCP Client)   \u2502   JSON-RPC     \u2502  (MCP Server)   \u2502   TCP/IP       \u2502  PLC        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ol> <li>Claude Desktop sends tool requests to the MCP server via JSON-RPC over stdio</li> <li>beckhoff_mcp translates these requests into ADS (Automation Device Specification) commands</li> <li>pyads library communicates with the TwinCAT runtime over TCP/IP</li> <li>Results are returned back through the chain to Claude</li> </ol>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#architecture","title":"Architecture","text":"<ul> <li>Transport: stdio (standard input/output)</li> <li>Protocol: JSON-RPC 2.0 (MCP standard)</li> <li>PLC Communication: ADS protocol via pyads library</li> <li>Discovery: UDP port 48899 for PLC discovery</li> <li>Operations: Read-only (no writing to PLC variables for safety)</li> <li>Startup: Graceful - starts even without a local PLC connection</li> </ul>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#installation-prerequisites","title":"Installation Prerequisites","text":""},{"location":"Beckhoff_MCP/DOCUMENTATION/#1-python-310-or-higher","title":"1. Python 3.10 or higher","text":"<p>Download from python.org or use your preferred Python distribution.</p> <p>Verify installation: <pre><code>python --version\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#2-beckhoff-twincat","title":"2. Beckhoff TwinCAT","text":"<p>You need TwinCAT installed on the machine where the MCP server runs. This provides: - The ADS communication layer - The <code>TcAdsDll.dll</code> library required by pyads</p> <p>TwinCAT can be: - TwinCAT XAE (Engineering environment) - includes everything - TwinCAT XAR (Runtime only) - sufficient if just connecting to PLCs - TwinCAT ADS (Communication library only) - minimal installation</p> <p>Download from Beckhoff website (requires registration).</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#3-ads-route-configuration","title":"3. ADS Route Configuration","text":"<p>For remote PLCs, you need to configure ADS routes: 1. Open TwinCAT XAE or the ADS Router 2. Add a route to your target PLC 3. Note the AMS Net ID (e.g., <code>192.168.1.100.1.1</code>)</p> <p>For local development with a simulated PLC, the default <code>127.0.0.1.1.1</code> works.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#4-claude-desktop","title":"4. Claude Desktop","text":"<p>Download from claude.ai - the MCP feature is available in the desktop application.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#installation","title":"Installation","text":""},{"location":"Beckhoff_MCP/DOCUMENTATION/#option-1-install-from-source-recommended","title":"Option 1: Install from source (recommended)","text":"<pre><code># Navigate to the project directory\ncd path/to/beckhoff_mcp\n\n# Install in editable mode (allows you to modify the code)\npip install -e .\n</code></pre>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#option-2-install-dependencies-manually","title":"Option 2: Install dependencies manually","text":"<pre><code>pip install mcp pyads pydantic\n</code></pre> <p>Then run directly: <pre><code>python -m beckhoff_mcp.server\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#uninstallation","title":"Uninstallation","text":"<p>To uninstall before upgrading to a new version:</p> <pre><code># Uninstall the package\npip uninstall beckhoff_mcp\n\n# Verify it's removed\npip show beckhoff_mcp\n# Should output: WARNING: Package(s) not found: beckhoff_mcp\n</code></pre>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#configuration","title":"Configuration","text":""},{"location":"Beckhoff_MCP/DOCUMENTATION/#1-configure-the-mcp-server","title":"1. Configure the MCP Server","text":"<p>Edit <code>src/beckhoff_mcp/server.py</code> to set your PLC connection details:</p> <pre><code># Default connection settings (near the top of the file)\nAMS_NET_ID = \"127.0.0.1.1.1\"  # Change to your PLC's AMS Net ID\nAMS_PORT = 851                 # TwinCAT 3 PLC Runtime 1 (851-854)\n</code></pre> <p>Disconnected Mode: If no local PLC is available on startup (e.g., TwinCAT is not running or is in Config mode), the server will start in disconnected mode. You can then use <code>beckhoff_discover_and_connect</code> to connect to a remote PLC. All tools will return helpful error messages indicating you need to connect first.</p> <p>Common port numbers: | Port | Description | |------|-------------| | 851  | TwinCAT 3 PLC Runtime 1 | | 852  | TwinCAT 3 PLC Runtime 2 | | 853  | TwinCAT 3 PLC Runtime 3 | | 854  | TwinCAT 3 PLC Runtime 4 |</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#2-configure-claude-desktop","title":"2. Configure Claude Desktop","text":"<p>Create or edit <code>%APPDATA%\\Claude\\claude_desktop_config.json</code>:</p> <p>Windows path: <code>C:\\Users\\&lt;username&gt;\\AppData\\Roaming\\Claude\\claude_desktop_config.json</code></p> <pre><code>{\n  \"mcpServers\": {\n    \"beckhoff_mcp\": {\n      \"command\": \"beckhoff_mcp\"\n    }\n  }\n}\n</code></pre> <p>Or with full path: <pre><code>{\n  \"mcpServers\": {\n    \"beckhoff_mcp\": {\n      \"command\": \"C:\\\\Python310\\\\Scripts\\\\beckhoff_mcp.exe\"\n    }\n  }\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#3-restart-claude-desktop","title":"3. Restart Claude Desktop","text":"<p>After saving the config, fully restart Claude Desktop (quit and reopen) for changes to take effect.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#dynamic-plc-connection","title":"Dynamic PLC Connection","text":"<p>Instead of editing configuration files, you can connect to remote PLCs at runtime using natural language:</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#basic-discovery-route-pre-configured","title":"Basic Discovery (Route Pre-configured)","text":"<pre><code>&lt;beckhoff:mcp: ip=192.168.1.54&gt;\n</code></pre> <p>Or simply: <pre><code>Connect to the PLC at 192.168.1.54\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#with-automatic-route-creation","title":"With Automatic Route Creation","text":"<p>If the ADS route doesn't exist, provide credentials: <pre><code>Connect to PLC at 192.168.1.54 with username admin and password secret\n</code></pre></p> <p>The server will: 1. Send UDP discovery packet to port 48899 2. Retrieve the PLC's AMS Net ID 3. Add an ADS route (if credentials provided) 4. Connect and cache all symbols 5. Replace the current connection</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#available-tools","title":"Available Tools","text":""},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_get_device_info","title":"beckhoff_get_device_info","text":"<p>Get PLC device name and version information.</p> <p>Example prompt: \"Get the Beckhoff PLC device info\"</p> <p>Returns: <pre><code>{\n  \"device_name\": \"PLC_Project\",\n  \"version\": {\n    \"version\": 3,\n    \"revision\": 1,\n    \"build\": 4024\n  }\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_get_device_state","title":"beckhoff_get_device_state","text":"<p>Get current ADS state and device state.</p> <p>Example prompt: \"What is the current state of the PLC?\"</p> <p>Returns: <pre><code>{\n  \"ads_state\": {\n    \"code\": 5,\n    \"name\": \"Run\"\n  },\n  \"device_state\": 0\n}\n</code></pre></p> <p>ADS States: | Code | Name | Description | |------|------|-------------| | 0 | Invalid | Invalid state | | 1 | Idle | Idle | | 5 | Run | PLC is running | | 6 | Stop | PLC is stopped | | 15 | Config | Configuration mode |</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_list_symbols","title":"beckhoff_list_symbols","text":"<p>List available PLC symbols with optional filtering and pagination.</p> <p>Example prompts: - \"List all PLC symbols\" - \"Show symbols containing 'Motor'\" - \"List symbols in the GVL namespace\"</p> <p>Parameters: - <code>filter</code> (optional): Wildcard pattern (e.g., <code>*Motor*</code>, <code>GVL.*</code>) - <code>limit</code> (optional): Max results (default 50) - <code>offset</code> (optional): Pagination offset</p> <p>Returns: <pre><code>{\n  \"symbols\": [\n    {\"name\": \"MAIN.bStart\", \"type\": \"BOOL\", \"comment\": \"Start button\"},\n    {\"name\": \"MAIN.nCounter\", \"type\": \"INT\", \"comment\": \"Cycle counter\"}\n  ],\n  \"pagination\": {\n    \"total\": 150,\n    \"offset\": 0,\n    \"limit\": 50,\n    \"returned\": 50,\n    \"has_more\": true,\n    \"next_offset\": 50\n  }\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_get_symbol_info","title":"beckhoff_get_symbol_info","text":"<p>Get detailed information about a specific symbol.</p> <p>Example prompt: \"Get info about the symbol MAIN.bStart\"</p> <p>Returns: <pre><code>{\n  \"name\": \"MAIN.bStart\",\n  \"type\": \"BOOL\",\n  \"index_group\": 16448,\n  \"index_offset\": 0,\n  \"size\": 1,\n  \"comment\": \"Start button\"\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_read_variable","title":"beckhoff_read_variable","text":"<p>Read a single PLC variable by symbol name.</p> <p>Example prompts: - \"Read the value of MAIN.nCounter\" - \"What is the current value of GVL.rTemperature?\"</p> <p>Returns: <pre><code>{\n  \"name\": \"MAIN.nCounter\",\n  \"type\": \"INT\",\n  \"value\": 42\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_read_variables","title":"beckhoff_read_variables","text":"<p>Read multiple PLC variables at once.</p> <p>Example prompt: \"Read MAIN.bStart, MAIN.bStop, and MAIN.nCounter\"</p> <p>Returns: <pre><code>{\n  \"results\": [\n    {\"name\": \"MAIN.bStart\", \"type\": \"BOOL\", \"value\": true},\n    {\"name\": \"MAIN.bStop\", \"type\": \"BOOL\", \"value\": false},\n    {\"name\": \"MAIN.nCounter\", \"type\": \"INT\", \"value\": 42}\n  ],\n  \"errors\": null,\n  \"summary\": {\n    \"requested\": 3,\n    \"successful\": 3,\n    \"failed\": 0\n  }\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_discover_and_connect","title":"beckhoff_discover_and_connect","text":"<p>Discover and connect to a remote PLC by IP address using UDP discovery (port 48899).</p> <p>Example prompts: - <code>&lt;beckhoff:mcp: ip=192.168.1.54&gt;</code> - \"Connect to the PLC at 192.168.1.54\" - \"Connect to PLC at 10.0.0.100 with username admin and password secret\"</p> <p>Parameters: - <code>ip_address</code> (required): IP address of the target PLC - <code>username</code> (optional): PLC login username for route creation - <code>password</code> (optional): PLC login password for route creation - <code>ams_port</code> (optional, default 851): ADS port number - <code>route_name</code> (optional): Custom name for the ADS route</p> <p>Returns (success): <pre><code>{\n  \"success\": true,\n  \"ip_address\": \"192.168.1.54\",\n  \"discovered_ams_net_id\": \"192.168.1.54.1.1\",\n  \"ams_port\": 851,\n  \"route_added\": true,\n  \"device_info\": {\n    \"device_name\": \"CX-12345\",\n    \"version\": {\"version\": 3, \"revision\": 1, \"build\": 4024}\n  },\n  \"symbols_cached\": 150\n}\n</code></pre></p> <p>Returns (failure): <pre><code>{\n  \"success\": false,\n  \"error\": \"UDP discovery failed for 192.168.1.54: timed out\",\n  \"hint\": \"Ensure the PLC is reachable and UDP port 48899 is not blocked\"\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_connection_status","title":"beckhoff_connection_status","text":"<p>Get information about the current PLC connection.</p> <p>Example prompt: \"What PLC am I connected to?\"</p> <p>Returns: <pre><code>{\n  \"ams_net_id\": \"192.168.1.54.1.1\",\n  \"ams_port\": 851,\n  \"ip_address\": \"192.168.1.54\",\n  \"is_remote\": true,\n  \"is_connected\": true,\n  \"symbols_cached\": 150\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#ethercat-diagnostic-tools","title":"EtherCAT Diagnostic Tools","text":"<p>These tools provide read-only access to EtherCAT master and slave information via ADS port 0xFFFF (65535).</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_get_ethercat_master_state","title":"beckhoff_get_ethercat_master_state","text":"<p>Get the EtherCAT master state.</p> <p>Example prompt: \"What is the EtherCAT master state?\"</p> <p>Returns: <pre><code>{\n  \"master_state\": {\n    \"code\": 8,\n    \"name\": \"Op\"\n  },\n  \"ams_net_id\": \"192.168.1.54.1.1\",\n  \"ethercat_port\": 65535\n}\n</code></pre></p> <p>EtherCAT Master States: | Code | Name | Description | |------|------|-------------| | 0 | Unknown | Unknown state | | 1 | Init | Initialization | | 2 | PreOp | Pre-Operational | | 3 | Bootstrap | Bootstrap mode | | 4 | SafeOp | Safe-Operational | | 8 | Op | Operational |</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_get_ethercat_slave_count","title":"beckhoff_get_ethercat_slave_count","text":"<p>Get the number of EtherCAT slaves connected to the master.</p> <p>Example prompt: \"How many EtherCAT slaves are connected?\"</p> <p>Returns: <pre><code>{\n  \"slave_count\": 5,\n  \"ams_net_id\": \"192.168.1.54.1.1\"\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_get_ethercat_topology","title":"beckhoff_get_ethercat_topology","text":"<p>Get the EtherCAT network topology with all slave information.</p> <p>Example prompt: \"Show me the EtherCAT topology\" or \"List all EtherCAT slaves\"</p> <p>Returns: <pre><code>{\n  \"slave_count\": 3,\n  \"slaves\": [\n    {\n      \"address\": 1,\n      \"state\": {\"code\": 8, \"name\": \"Op\"},\n      \"vendor_id\": 2,\n      \"product_code\": 100663346\n    },\n    {\n      \"address\": 2,\n      \"state\": {\"code\": 8, \"name\": \"Op\"},\n      \"vendor_id\": 2,\n      \"product_code\": 100728882\n    },\n    {\n      \"address\": 3,\n      \"state\": {\"code\": 8, \"name\": \"Op\"},\n      \"vendor_id\": 2,\n      \"product_code\": 100794418\n    }\n  ],\n  \"ams_net_id\": \"192.168.1.54.1.1\"\n}\n</code></pre></p> <p>EtherCAT Slave States: | Code | Name | Description | |------|------|-------------| | 0x01 | Init | Initialization | | 0x02 | PreOp | Pre-Operational | | 0x03 | Bootstrap | Bootstrap mode | | 0x04 | SafeOp | Safe-Operational | | 0x08 | Op | Operational | | 0x10 | Error | Error state |</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_get_ethercat_slave_info","title":"beckhoff_get_ethercat_slave_info","text":"<p>Get detailed information about a specific EtherCAT slave.</p> <p>Example prompt: \"Get info about EtherCAT slave 1\"</p> <p>Parameters: - <code>slave_address</code> (required): The EtherCAT slave address (1-indexed)</p> <p>Returns: <pre><code>{\n  \"address\": 1,\n  \"state\": {\n    \"code\": 8,\n    \"name\": \"Op\"\n  },\n  \"vendor_id\": 2,\n  \"product_code\": 100663346,\n  \"crc_errors\": 0,\n  \"ams_net_id\": \"192.168.1.54.1.1\"\n}\n</code></pre></p> <p>Note: Vendor ID 2 is Beckhoff Automation. Product codes can be looked up in the Beckhoff device catalog.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#custom-ads-port-tools","title":"Custom ADS Port Tools","text":"<p>Some EtherCAT devices (like EK1200 EtherCAT Couplers) expose their I/O data on custom ADS ports rather than the standard EtherCAT master port (0xFFFF). These tools allow you to query and read from any ADS port.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_query_ads_port","title":"beckhoff_query_ads_port","text":"<p>Query a custom ADS port to discover available symbols and device information.</p> <p>Example prompts: - \"Query ADS port 27905\" - \"What symbols are available on port 0x6D01?\" - \"Check if there's an ADS server on port 27905\"</p> <p>Parameters: - <code>ads_port</code> (required): The ADS port number (e.g., 27905 or 0x6D01)</p> <p>Returns: <pre><code>{\n  \"ads_port\": 27905,\n  \"ads_port_hex\": \"0x6D01\",\n  \"ams_net_id\": \"5.59.203.226.1.1\",\n  \"ip_address\": \"192.168.1.67\",\n  \"success\": true,\n  \"device_info\": {\n    \"device_name\": \"EK1200\",\n    \"version\": {\"version\": 3, \"revision\": 1, \"build\": 4024}\n  },\n  \"state\": {\n    \"ads_state\": {\"code\": 5, \"name\": \"Run\"},\n    \"device_state\": 0\n  },\n  \"symbol_count\": 4,\n  \"symbols_preview\": [\n    {\"name\": \"Inputs.EL1008.Channel 1.Input\", \"type\": \"BOOL\"},\n    {\"name\": \"Outputs.EL2008.Channel 1.Output\", \"type\": \"BOOL\"}\n  ]\n}\n</code></pre></p> <p>How to find the ADS port: In TwinCAT XAE, double-click on the device (e.g., under I/O &gt; Devices &gt; EtherCAT), go to the \"ADS\" tab, check \"Enable ADS Server\", and note the \"ADS Server Port\" value.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#beckhoff_read_from_port","title":"beckhoff_read_from_port","text":"<p>Read a variable from a custom ADS port.</p> <p>Example prompts: - \"Read 'Inputs.EL1008.Channel 1.Input' from port 27905\" - \"Get the value of 'Outputs.EL2008.Channel 1.Output' on ADS port 27905\"</p> <p>Parameters: - <code>ads_port</code> (required): The ADS port number (e.g., 27905) - <code>symbol_name</code> (required): The symbol name to read</p> <p>Returns: <pre><code>{\n  \"name\": \"Inputs.EL1008.Channel 1.Input\",\n  \"type\": \"BOOL\",\n  \"value\": true,\n  \"ads_port\": 27905\n}\n</code></pre></p> <p>When to use these tools: - The standard EtherCAT diagnostic tools return \"Target port not found\" (ADS error 6) - You're working with EK1200 EtherCAT Couplers or similar devices - I/O data is exposed on a custom port configured in TwinCAT XAE</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#supported-data-types","title":"Supported Data Types","text":"TwinCAT Type Description Python Type BOOL Boolean bool BYTE 8-bit unsigned int SINT 8-bit signed int USINT 8-bit unsigned int INT 16-bit signed int UINT 16-bit unsigned int DINT 32-bit signed int UDINT 32-bit unsigned int LINT 64-bit signed int ULINT 64-bit unsigned int REAL 32-bit float float LREAL 64-bit float float STRING Text string str TIME, DATE, DT, TOD Time types int (ms) WORD, DWORD, LWORD Bit strings int <p>Note: Complex types (arrays, structures, function blocks) are identified but cannot be read directly. Use individual element access for structured data.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Beckhoff_MCP/DOCUMENTATION/#could-not-find-module-tcadsdlldll","title":"\"Could not find module 'TcAdsDll.dll'\"","text":"<p>Cause: TwinCAT ADS library not found in system PATH.</p> <p>Solution: The MCP server automatically adds common TwinCAT paths. If you have a non-standard installation, edit <code>server.py</code>:</p> <pre><code>twincat_paths = [\n    r\"C:\\TwinCAT\\Common64\",\n    r\"C:\\TwinCAT\\Common32\",\n    r\"C:\\YourCustomPath\",  # Add your path here\n]\n</code></pre>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#failed-to-connect-to-plc","title":"\"Failed to connect to PLC\"","text":"<p>Causes: 1. TwinCAT not running 2. Wrong AMS Net ID or port 3. ADS route not configured 4. Firewall blocking ADS (port 48898)</p> <p>Solutions: 1. Start TwinCAT System Service 2. Verify AMS Net ID in TwinCAT XAE (Target Browser) 3. Add ADS route for remote PLCs 4. Allow TCP port 48898 in firewall</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#udp-discovery-failed","title":"\"UDP discovery failed\"","text":"<p>Causes: 1. PLC not reachable on network 2. UDP port 48899 blocked by firewall 3. PLC discovery service disabled</p> <p>Solutions: 1. Verify PLC is reachable (<code>ping &lt;ip_address&gt;</code>) 2. Allow UDP port 48899 in firewall (both directions) 3. Check PLC has ADS discovery enabled (default is enabled)</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#symbol-not-found","title":"\"Symbol not found\"","text":"<p>Causes: 1. Typo in symbol name 2. Symbol doesn't exist in running project 3. Case sensitivity issue</p> <p>Solutions: 1. Use <code>beckhoff_list_symbols</code> to find correct name 2. Ensure PLC project is activated 3. Symbol names are case-sensitive - match exactly</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#not-connected-to-a-plc","title":"\"Not connected to a PLC\"","text":"<p>Cause: Server started in disconnected mode because no local PLC was available.</p> <p>Solutions: 1. Use <code>beckhoff_discover_and_connect</code> to connect to a remote PLC 2. Start TwinCAT locally and restart the MCP server 3. Check <code>beckhoff_connection_status</code> to see current connection state</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#target-port-not-found-ads-error-6","title":"\"Target port not found\" (ADS Error 6)","text":"<p>Causes: 1. EtherCAT ADS Server not enabled 2. Wrong ADS port number 3. Device uses custom ADS port instead of 0xFFFF</p> <p>Solutions: 1. In TwinCAT XAE, double-click the device, go to \"ADS\" tab, enable \"Enable ADS Server\" 2. Note the \"ADS Server Port\" value (e.g., 27905) 3. Use <code>beckhoff_query_ads_port</code> with the correct port number 4. Activate the TwinCAT configuration after enabling ADS Server</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#mcp-server-not-appearing-in-claude-desktop","title":"MCP Server not appearing in Claude Desktop","text":"<p>Solutions: 1. Verify config file path: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> 2. Check JSON syntax (no trailing commas, proper escaping) 3. Fully restart Claude Desktop (not just close window) 4. Check logs: <code>%APPDATA%\\Claude\\logs\\mcp-server-beckhoff_mcp.log</code></p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#project-structure","title":"Project Structure","text":"<pre><code>beckhoff_mcp/\n\u251c\u2500\u2500 pyproject.toml              # Package configuration\n\u251c\u2500\u2500 README.md                   # Quick start guide\n\u251c\u2500\u2500 DOCUMENTATION.md            # This file\n\u251c\u2500\u2500 beckhoff_mcp_tasklist.md    # Original implementation plan\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 beckhoff_mcp/\n        \u251c\u2500\u2500 __init__.py         # Package marker\n        \u2514\u2500\u2500 server.py           # MCP server implementation\n</code></pre>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#security-considerations","title":"Security Considerations","text":"<ul> <li>Read-only: The server only reads data; it cannot modify PLC variables</li> <li>Local execution: The MCP server runs locally on your machine</li> <li>No network exposure: Communication with Claude is via stdio, not network sockets</li> <li>No authentication: Relies on TwinCAT's ADS security model</li> <li>Credentials in prompts: When using <code>beckhoff_discover_and_connect</code> with credentials, be aware that username/password may be visible in conversation history</li> </ul>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#extending-the-server","title":"Extending the Server","text":""},{"location":"Beckhoff_MCP/DOCUMENTATION/#adding-write-capability","title":"Adding Write Capability","text":"<p>To add write functionality (use with caution):</p> <pre><code>@mcp.tool()\ndef beckhoff_write_variable(ctx: Context, symbol_name: str, value: Any) -&gt; dict[str, Any]:\n    \"\"\"Write a value to a PLC variable.\"\"\"\n    state: AppState = ctx.request_context.lifespan_context\n    plc = state.plc\n\n    symbol = state.symbols.get(symbol_name)\n    if not symbol:\n        return {\"error\": f\"Symbol '{symbol_name}' not found\"}\n\n    plc_type = get_plc_type(symbol.symbol_type)\n    plc.write_by_name(symbol_name, value, plc_type)\n\n    return {\"success\": True, \"symbol\": symbol_name, \"value\": value}\n</code></pre>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#adding-custom-tools","title":"Adding Custom Tools","text":"<p>Follow the pattern in <code>server.py</code>:</p> <pre><code>@mcp.tool(annotations=TOOL_ANNOTATIONS)\ndef my_custom_tool(ctx: Context, param1: str) -&gt; dict[str, Any]:\n    \"\"\"Tool description shown to Claude.\"\"\"\n    state: AppState = ctx.request_context.lifespan_context\n    plc = state.plc\n\n    # Your implementation here\n    return {\"result\": \"...\"}\n</code></pre>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#dependencies","title":"Dependencies","text":"Package Version Purpose mcp &gt;=1.0.0 MCP protocol implementation pyads &gt;=3.3.0 Beckhoff ADS communication pydantic &gt;=2.0.0 Data validation"},{"location":"Beckhoff_MCP/DOCUMENTATION/#license","title":"License","text":"<p>MIT License - See LICENSE file for details.</p>"},{"location":"Beckhoff_MCP/DOCUMENTATION/#resources","title":"Resources","text":"<ul> <li>MCP Documentation</li> <li>pyads Documentation</li> <li>Beckhoff Information System</li> <li>TwinCAT ADS Protocol</li> </ul>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/","title":"Using Beckhoff MCP with LM Studio","text":"<p>This guide explains how to configure LM Studio to use the Beckhoff MCP server for PLC communication.</p>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#prerequisites","title":"Prerequisites","text":"<ul> <li>LM Studio installed (version with MCP support)</li> <li>Python 3.10+ installed</li> <li>Beckhoff MCP installed via pip</li> </ul>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#installation","title":"Installation","text":""},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#1-install-beckhoff-mcp","title":"1. Install Beckhoff MCP","text":"<pre><code># Install from source (editable mode)\npip install -e /path/to/beckhoff_mcp\n\n# Or install from package\npip install beckhoff-mcp\n</code></pre>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#2-verify-installation","title":"2. Verify Installation","text":"<pre><code>python -c \"import beckhoff_mcp; print(beckhoff_mcp.__file__)\"\n</code></pre> <p>This should print the path to the installed module. If you get <code>ModuleNotFoundError</code>, see Troubleshooting.</p>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#lm-studio-configuration","title":"LM Studio Configuration","text":""},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#1-create-or-edit-mcpjson","title":"1. Create or Edit mcp.json","text":"<p>LM Studio uses an <code>mcp.json</code> file to configure MCP servers. Create this file with the following content:</p> <pre><code>{\n  \"mcpServers\": {\n    \"beckhoff\": {\n      \"command\": \"C:\\\\Python310\\\\python.exe\",\n      \"args\": [\"-m\", \"beckhoff_mcp.server\"]\n    }\n  }\n}\n</code></pre> <p>Important: Replace <code>C:\\\\Python310\\\\python.exe</code> with the full path to your Python installation where beckhoff_mcp is installed.</p>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#2-find-your-python-path","title":"2. Find Your Python Path","text":"<p>To find the correct Python path:</p> <p>Windows: <pre><code>where python\n</code></pre></p> <p>Linux/macOS: <pre><code>which python\n</code></pre></p> <p>If you have multiple Python installations, verify which one has beckhoff_mcp:</p> <pre><code># Test each Python installation\nC:\\Python310\\python.exe -c \"import beckhoff_mcp; print('OK')\"\nC:\\Python312\\python.exe -c \"import beckhoff_mcp; print('OK')\"\n</code></pre>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#3-load-the-mcp-in-lm-studio","title":"3. Load the MCP in LM Studio","text":"<ol> <li>Open LM Studio</li> <li>Navigate to Integrations (puzzle piece icon)</li> <li>Click Install dropdown</li> <li>Add your MCP configuration or point to your <code>mcp.json</code> file</li> <li>Toggle the beckhoff integration ON</li> </ol>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#configuration-examples","title":"Configuration Examples","text":""},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#windows-python-installed-globally","title":"Windows (Python installed globally)","text":"<pre><code>{\n  \"mcpServers\": {\n    \"beckhoff\": {\n      \"command\": \"C:\\\\Python310\\\\python.exe\",\n      \"args\": [\"-m\", \"beckhoff_mcp.server\"]\n    }\n  }\n}\n</code></pre>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#windows-python-from-windows-store","title":"Windows (Python from Windows Store)","text":"<pre><code>{\n  \"mcpServers\": {\n    \"beckhoff\": {\n      \"command\": \"C:\\\\Users\\\\YourName\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\"-m\", \"beckhoff_mcp.server\"]\n    }\n  }\n}\n</code></pre>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#linuxmacos","title":"Linux/macOS","text":"<pre><code>{\n  \"mcpServers\": {\n    \"beckhoff\": {\n      \"command\": \"/usr/bin/python3\",\n      \"args\": [\"-m\", \"beckhoff_mcp.server\"]\n    }\n  }\n}\n</code></pre>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#using-virtual-environment","title":"Using Virtual Environment","text":"<pre><code>{\n  \"mcpServers\": {\n    \"beckhoff\": {\n      \"command\": \"C:\\\\projects\\\\myenv\\\\Scripts\\\\python.exe\",\n      \"args\": [\"-m\", \"beckhoff_mcp.server\"]\n    }\n  }\n}\n</code></pre>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#using-uv","title":"Using UV","text":"<pre><code>{\n  \"mcpServers\": {\n    \"beckhoff\": {\n      \"command\": \"uv\",\n      \"args\": [\"run\", \"--directory\", \"C:\\\\projects\\\\beckhoff_mcp\\\\beckhoff_mcp_v0.3.0\\\\beckhoff_mcp\", \"beckhoff-mcp\"]\n    }\n  }\n}\n</code></pre>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#recommended-llm-models","title":"Recommended LLM Models","text":"<p>MCP tool calling requires models with strong instruction-following and function-calling capabilities. Not all models perform equally well.</p>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#highly-recommended","title":"Highly Recommended","text":"Model Parameters Notes Qwen2.5-Instruct 7B, 14B, 32B Excellent tool-calling, best overall choice Llama-3.1-Instruct 8B, 70B Strong tool support, well-tested Mistral-Instruct 7B Good balance of speed and capability Hermes-3 8B, 70B Fine-tuned for function calling"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#acceptable","title":"Acceptable","text":"Model Parameters Notes Gemma-2 9B, 27B Decent tool support Phi-3 14B Microsoft's capable small model DeepSeek-Coder 6.7B, 33B Good for technical tasks"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#not-recommended","title":"Not Recommended","text":"Model Reason Models &lt; 4B parameters Struggle with complex tool workflows Base models (non-Instruct) Not fine-tuned for instructions Older model versions Lack function-calling training"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#model-selection-tips","title":"Model Selection Tips","text":"<ol> <li>Start with 7B+ parameters - Smaller models often loop or fail to process tool results</li> <li>Use Instruct/Chat variants - Base models don't follow tool-calling formats</li> <li>Quantization matters - Q4_K_M or higher recommended; Q2/Q3 may reduce tool accuracy</li> <li>Context length - Ensure model supports enough context for your PLC's symbol list</li> </ol>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#beckhoff-mcp-is-not-recognized","title":"\"beckhoff-mcp is not recognized\"","text":"<p>Cause: The command isn't in system PATH.</p> <p>Solution: Use the full Python path instead: <pre><code>{\n  \"command\": \"C:\\\\Python310\\\\python.exe\",\n  \"args\": [\"-m\", \"beckhoff_mcp.server\"]\n}\n</code></pre></p>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#modulenotfounderror-no-module-named-beckhoff_mcp","title":"\"ModuleNotFoundError: No module named 'beckhoff_mcp'\"","text":"<p>Cause: Package not installed in the Python installation LM Studio is using.</p> <p>Solutions:</p> <ol> <li> <p>Verify which Python has the module:    <pre><code>python -c \"import beckhoff_mcp; print(beckhoff_mcp.__file__)\"\n</code></pre></p> </li> <li> <p>Install in the correct Python:    <pre><code>C:\\Python310\\python.exe -m pip install -e /path/to/beckhoff_mcp\n</code></pre></p> </li> <li> <p>Check for corrupted installations:    <pre><code>pip show beckhoff-mcp\n</code></pre>    Look for warnings about \"invalid distribution\". If found:    <pre><code>pip uninstall beckhoff-mcp\n# Remove any ~eckhoff* folders in site-packages\npip install -e /path/to/beckhoff_mcp\n</code></pre></p> </li> </ol>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#connection-closed-mcp-error-32000","title":"\"Connection closed\" / MCP error -32000","text":"<p>Cause: The MCP server process crashed or failed to start.</p> <p>Solutions:</p> <ol> <li> <p>Test the server manually:    <pre><code>C:\\Python310\\python.exe -m beckhoff_mcp.server\n</code></pre></p> </li> <li> <p>Check for missing dependencies:    <pre><code>pip install pyads mcp pydantic\n</code></pre></p> </li> <li> <p>Verify pyads can load (Windows-specific):    <pre><code>python -c \"import pyads; print(pyads.__version__)\"\n</code></pre></p> </li> </ol>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#model-loops-on-tool-calls","title":"Model loops on tool calls","text":"<p>Cause: The LLM model struggles with tool-calling workflows.</p> <p>Solutions:</p> <ol> <li>Switch to a more capable model (Qwen2.5-7B-Instruct recommended)</li> <li>Use simpler prompts: \"List available Beckhoff tools\" instead of complex requests</li> <li>Try a larger quantization (Q5 or Q6 instead of Q4)</li> </ol>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#not-connected-to-a-plc-errors","title":"\"Not connected to a PLC\" errors","text":"<p>Cause: The MCP started in disconnected mode (no local PLC available).</p> <p>Solution: This is normal behavior. Use the <code>beckhoff_discover_and_connect</code> tool to connect to a remote PLC: <pre><code>Connect to the Beckhoff PLC at IP address 192.168.1.100\n</code></pre></p>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#tools-appear-but-dont-work","title":"Tools appear but don't work","text":"<p>Cause: Model generates malformed tool calls.</p> <p>Solutions:</p> <ol> <li>Check LM Studio logs for the exact error</li> <li>Try a different model with better function-calling support</li> <li>Ensure model temperature is reasonable (0.7 or lower for tool use)</li> </ol>"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#available-tools","title":"Available Tools","text":"<p>Once configured, these tools become available to the LLM:</p> Tool Description <code>beckhoff_get_device_info</code> Get PLC device name and version <code>beckhoff_get_device_state</code> Get current ADS state (Run, Stop, etc.) <code>beckhoff_list_symbols</code> List/search PLC symbols with pagination <code>beckhoff_get_symbol_info</code> Get detailed symbol metadata <code>beckhoff_read_variable</code> Read a single PLC variable <code>beckhoff_read_variables</code> Batch read multiple variables <code>beckhoff_discover_and_connect</code> Connect to a PLC by IP address <code>beckhoff_connection_status</code> Check current connection status <code>beckhoff_disconnect</code> Disconnect from current PLC <code>beckhoff_get_plc_time</code> Get PLC system time <code>beckhoff_query_ads_port</code> Query device info on custom ADS port <code>beckhoff_read_from_port</code> Read symbol from custom ADS port"},{"location":"Beckhoff_MCP/LM_STUDIO_GUIDE/#example-prompts","title":"Example Prompts","text":"<p>Once connected, try these prompts:</p> <pre><code>What is the current state of the PLC?\n</code></pre> <pre><code>List all symbols containing \"Motor\"\n</code></pre> <pre><code>Read the value of MAIN.bRunning\n</code></pre> <pre><code>Connect to the Beckhoff PLC at 192.168.1.100\n</code></pre> <pre><code>Show me the device info and current connection status\n</code></pre>"},{"location":"LLM/attention-and-weights-relationship/","title":"The Relationship Between Attention and Weights","text":""},{"location":"LLM/attention-and-weights-relationship/#the-short-answer","title":"The Short Answer","text":"<p>Weights are the stored, learned parameters. Attention is a computation that uses those weights to determine how tokens relate to each other at runtime.</p> <pre><code>Weights = Stored (learned during training)\nAttention Scores = Computed (calculated fresh for every input)\n</code></pre>"},{"location":"LLM/attention-and-weights-relationship/#the-two-types-of-weights-people-confuse","title":"The Two Types of \"Weights\" People Confuse","text":"Term What It Is Stored in GGUF? Model Weights Learned parameters (W_q, W_k, W_v matrices) \u2705 Yes Attention Weights/Scores Token-to-token relevance scores \u274c No (computed at runtime) <p>This naming collision causes confusion. When someone says \"attention weights,\" they usually mean the attention scores \u2014 which are not stored.</p>"},{"location":"LLM/attention-and-weights-relationship/#how-attention-works","title":"How Attention Works","text":"<pre><code>flowchart TB\n    subgraph STORED[\"STORED IN GGUF (Learned Parameters)\"]\n        WQ[\"W_q&lt;br/&gt;Query Weight Matrix&lt;br/&gt;[4096 \u00d7 4096]\"]\n        WK[\"W_k&lt;br/&gt;Key Weight Matrix&lt;br/&gt;[4096 \u00d7 4096]\"]\n        WV[\"W_v&lt;br/&gt;Value Weight Matrix&lt;br/&gt;[4096 \u00d7 4096]\"]\n        WO[\"W_o&lt;br/&gt;Output Weight Matrix&lt;br/&gt;[4096 \u00d7 4096]\"]\n    end\n\n    subgraph COMPUTED[\"COMPUTED AT RUNTIME\"]\n        Q[\"Queries (Q)\"]\n        K[\"Keys (K)\"]\n        V[\"Values (V)\"]\n        SCORES[\"Attention Scores&lt;br/&gt;(which tokens attend to which)\"]\n        OUT[\"Attention Output\"]\n    end\n\n    WQ --&gt; Q\n    WK --&gt; K\n    WV --&gt; V\n    Q &amp; K --&gt; SCORES\n    SCORES &amp; V --&gt; OUT\n    WO --&gt; OUT\n\n    style STORED fill:#4a90d9,stroke:#2c5282,color:#fff\n    style COMPUTED fill:#ed8936,stroke:#c05621,color:#fff</code></pre>"},{"location":"LLM/attention-and-weights-relationship/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":""},{"location":"LLM/attention-and-weights-relationship/#step-1-project-input-using-stored-weights","title":"Step 1: Project Input Using Stored Weights","text":"<p>For each token's embedding vector <code>x</code>:</p> <pre><code>Q = x \u00d7 W_q    (Query: \"What am I looking for?\")\nK = x \u00d7 W_k    (Key: \"What do I contain?\")\nV = x \u00d7 W_v    (Value: \"What information do I provide?\")\n</code></pre> <p>The weight matrices <code>W_q</code>, <code>W_k</code>, <code>W_v</code> are stored in the GGUF file. They were learned during training.</p>"},{"location":"LLM/attention-and-weights-relationship/#step-2-compute-attention-scores-runtime","title":"Step 2: Compute Attention Scores (Runtime)","text":"<pre><code>Attention_Scores = softmax( (Q \u00d7 K^T) / \u221ad )\n</code></pre> <p>This produces a matrix showing how much each token should \"pay attention\" to every other token.</p> <pre><code>flowchart LR\n    subgraph SCORE_MATRIX[\"ATTENTION SCORE MATRIX (Computed)\"]\n        direction TB\n        M[\"         The  cat  sat  on   mat\n        The  [1.0, 0.0, 0.0, 0.0, 0.0]\n        cat  [0.3, 0.5, 0.1, 0.0, 0.1]\n        sat  [0.2, 0.4, 0.2, 0.1, 0.1]\n        on   [0.1, 0.2, 0.3, 0.2, 0.2]\n        mat  [0.1, 0.3, 0.1, 0.2, 0.3]\"]\n    end\n\n    style SCORE_MATRIX fill:#f6e05e,stroke:#d69e2e,color:#333</code></pre> <p>This matrix is NOT stored \u2014 it's computed fresh for every input sequence.</p>"},{"location":"LLM/attention-and-weights-relationship/#step-3-apply-scores-to-values","title":"Step 3: Apply Scores to Values","text":"<pre><code>Output = Attention_Scores \u00d7 V\n</code></pre> <p>Each token's output is a weighted combination of all Value vectors, where the weights come from the attention scores.</p>"},{"location":"LLM/attention-and-weights-relationship/#step-4-project-through-output-weight","title":"Step 4: Project Through Output Weight","text":"<pre><code>Final_Output = Output \u00d7 W_o\n</code></pre> <p>The output weight matrix <code>W_o</code> is stored in the GGUF file.</p>"},{"location":"LLM/attention-and-weights-relationship/#visual-stored-vs-computed","title":"Visual: Stored vs Computed","text":"<pre><code>flowchart TB\n    subgraph GGUF[\"GGUF FILE (Stored)\"]\n        direction LR\n        W1[\"W_q\"]\n        W2[\"W_k\"]\n        W3[\"W_v\"]\n        W4[\"W_o\"]\n    end\n\n    subgraph RUNTIME[\"INFERENCE (Computed)\"]\n        direction TB\n        INPUT[\"Input: 'The cat sat'\"]\n        QKV[\"Q, K, V vectors\"]\n        ATT[\"Attention Scores&lt;br/&gt;(token relationships)\"]\n        OUTPUT[\"Output vectors\"]\n    end\n\n    GGUF --&gt;|\"used to compute\"| RUNTIME\n    INPUT --&gt; QKV --&gt; ATT --&gt; OUTPUT\n\n    style GGUF fill:#9f7aea,stroke:#6b46c1,color:#fff\n    style RUNTIME fill:#48bb78,stroke:#276749,color:#fff</code></pre>"},{"location":"LLM/attention-and-weights-relationship/#why-this-design","title":"Why This Design?","text":""},{"location":"LLM/attention-and-weights-relationship/#the-power-of-learned-projections","title":"The Power of Learned Projections","text":"<p>The weight matrices learn how to create good queries, keys, and values during training:</p> Matrix What It Learns <code>W_q</code> How to formulate \"questions\" about what information is needed <code>W_k</code> How to create \"labels\" describing what each token contains <code>W_v</code> How to package the actual information to be retrieved <code>W_o</code> How to combine multi-head outputs into a useful representation"},{"location":"LLM/attention-and-weights-relationship/#dynamic-relationships","title":"Dynamic Relationships","text":"<p>Because attention scores are computed at runtime:</p> <ul> <li>The same model can handle any input text</li> <li>Token relationships are context-dependent</li> <li>\"Bank\" attends to \"river\" differently than to \"money\"</li> </ul>"},{"location":"LLM/attention-and-weights-relationship/#multi-head-attention","title":"Multi-Head Attention","text":"<p>Real models use multiple attention \"heads\" in parallel:</p> <pre><code>flowchart TB\n    subgraph MULTIHEAD[\"MULTI-HEAD ATTENTION\"]\n        INPUT[\"Input\"]\n\n        subgraph HEADS[\"Parallel Attention Heads\"]\n            H1[\"Head 1&lt;br/&gt;W_q1, W_k1, W_v1\"]\n            H2[\"Head 2&lt;br/&gt;W_q2, W_k2, W_v2\"]\n            H3[\"Head 3&lt;br/&gt;W_q3, W_k3, W_v3\"]\n            HN[\"Head N&lt;br/&gt;...\"]\n        end\n\n        CONCAT[\"Concatenate\"]\n        WO[\"W_o (stored)\"]\n        OUTPUT[\"Output\"]\n    end\n\n    INPUT --&gt; H1 &amp; H2 &amp; H3 &amp; HN\n    H1 &amp; H2 &amp; H3 &amp; HN --&gt; CONCAT --&gt; WO --&gt; OUTPUT\n\n    style HEADS fill:#4a90d9,stroke:#2c5282,color:#fff\n    style WO fill:#9f7aea,stroke:#6b46c1,color:#fff</code></pre> <p>Each head has its own stored weight matrices but computes its own attention scores at runtime. Different heads can learn to focus on different types of relationships:</p> <ul> <li>Head 1: Syntactic relationships (subject-verb)</li> <li>Head 2: Positional relationships (nearby words)</li> <li>Head 3: Semantic relationships (synonyms, concepts)</li> </ul>"},{"location":"LLM/attention-and-weights-relationship/#concrete-example","title":"Concrete Example","text":"<p>Given the input: \"The cat sat on the mat\"</p>"},{"location":"LLM/attention-and-weights-relationship/#stored-in-gguf","title":"Stored (in GGUF):","text":"<pre><code>blk.0.attn_q.weight  = [4096 \u00d7 4096 matrix of floats]\nblk.0.attn_k.weight  = [4096 \u00d7 4096 matrix of floats]\nblk.0.attn_v.weight  = [4096 \u00d7 4096 matrix of floats]\nblk.0.attn_output.weight = [4096 \u00d7 4096 matrix of floats]\n</code></pre>"},{"location":"LLM/attention-and-weights-relationship/#computed-at-runtime","title":"Computed (at runtime):","text":"<pre><code>Q for \"cat\" = embedding(\"cat\") \u00d7 W_q = [0.12, -0.45, 0.89, ...]\nK for \"sat\" = embedding(\"sat\") \u00d7 W_k = [0.34, 0.21, -0.56, ...]\n\nAttention score (\"cat\" \u2192 \"sat\") = softmax(Q_cat \u00b7 K_sat / \u221ad) = 0.42\n</code></pre> <p>This score 0.42 means \"cat\" pays 42% of its attention to \"sat\" in this context.</p>"},{"location":"LLM/attention-and-weights-relationship/#the-attention-formula","title":"The Attention Formula","text":"<pre><code>Attention(Q, K, V) = softmax(Q \u00d7 K^T / \u221ad_k) \u00d7 V\n</code></pre> Component Source Stored? Q Input \u00d7 W_q W_q stored, Q computed K Input \u00d7 W_k W_k stored, K computed V Input \u00d7 W_v W_v stored, V computed \u221ad_k Constant (embedding dimension) N/A softmax(...) Attention scores Computed Final result Weighted sum of values Computed"},{"location":"LLM/attention-and-weights-relationship/#summary-table","title":"Summary Table","text":"Concept Stored in GGUF? Purpose W_q, W_k, W_v, W_o \u2705 Yes Transform inputs into Q, K, V Attention scores \u274c No Determine token-to-token relevance Q, K, V vectors \u274c No Intermediate representations Final attention output \u274c No Contextualized token representations"},{"location":"LLM/attention-and-weights-relationship/#key-insight","title":"Key Insight","text":"<pre><code>flowchart LR\n    subgraph RELATIONSHIP[\"THE RELATIONSHIP\"]\n        WEIGHTS[\"Stored Weights&lt;br/&gt;(learned parameters)\"]\n        ATTENTION[\"Attention Mechanism&lt;br/&gt;(runtime computation)\"]\n        MEANING[\"Contextual Meaning&lt;br/&gt;(output)\"]\n\n        WEIGHTS --&gt;|\"enable\"| ATTENTION --&gt;|\"produces\"| MEANING\n    end\n\n    style WEIGHTS fill:#9f7aea,stroke:#6b46c1,color:#fff\n    style ATTENTION fill:#ed8936,stroke:#c05621,color:#fff\n    style MEANING fill:#48bb78,stroke:#276749,color:#fff</code></pre> <p>Weights are the \"recipe\" \u2014 they define the transformations. Attention is the \"cooking\" \u2014 it applies those transformations to produce context-aware understanding.</p> <p>The weights learn how to compute good attention. The attention scores themselves emerge from the input.</p> <p>Guide explaining the relationship between attention and weights in transformer models</p>"},{"location":"LLM/gguf-file-structure-guide/","title":"GGUF File Format: Complete Structural Guide","text":""},{"location":"LLM/gguf-file-structure-guide/#overview","title":"Overview","text":"<p>GGUF (GPT-Generated Unified Format) is a binary file format designed for storing large language models. It is the successor to the older GGML format and is primarily used by llama.cpp and compatible inference engines. GGUF is optimized for fast loading, memory-mapped access, and single-file distribution of quantized models.</p>"},{"location":"LLM/gguf-file-structure-guide/#high-level-file-structure","title":"High-Level File Structure","text":"<p>A GGUF file is organized into four major logical regions, read sequentially:</p> <pre><code>flowchart TB\n    subgraph GGUF[\"GGUF FILE STRUCTURE\"]\n        direction TB\n        A[\"\ud83d\udccb HEADER&lt;br/&gt;Magic + Version + Counts\"]\n        B[\"\ud83c\udff7\ufe0f METADATA KV PAIRS&lt;br/&gt;Model Configuration\"]\n        C[\"\ud83d\udcd0 TENSOR INFOS&lt;br/&gt;Tensor Descriptors\"]\n        D[\"\ud83d\udcbe TENSOR DATA&lt;br/&gt;Quantized Weights\"]\n    end\n\n    A --&gt; B --&gt; C --&gt; D\n\n    style A fill:#4a90d9,stroke:#2c5282,color:#fff\n    style B fill:#48bb78,stroke:#276749,color:#fff\n    style C fill:#ed8936,stroke:#c05621,color:#fff\n    style D fill:#9f7aea,stroke:#6b46c1,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#section-1-header","title":"Section 1: Header","text":"<p>The header is the first 24 bytes of every GGUF file and contains essential identification and counting information.</p>"},{"location":"LLM/gguf-file-structure-guide/#header-layout","title":"Header Layout","text":"<pre><code>flowchart LR\n    subgraph HEADER[\"HEADER (24 bytes)\"]\n        direction LR\n        M[\"MAGIC&lt;br/&gt;4 bytes&lt;br/&gt;'GGUF'\"]\n        V[\"VERSION&lt;br/&gt;4 bytes&lt;br/&gt;uint32\"]\n        T[\"TENSOR_COUNT&lt;br/&gt;8 bytes&lt;br/&gt;uint64\"]\n        K[\"METADATA_KV_COUNT&lt;br/&gt;8 bytes&lt;br/&gt;uint64\"]\n    end\n\n    M --&gt; V --&gt; T --&gt; K\n\n    style M fill:#e53e3e,stroke:#c53030,color:#fff\n    style V fill:#dd6b20,stroke:#c05621,color:#fff\n    style T fill:#d69e2e,stroke:#b7791f,color:#fff\n    style K fill:#38a169,stroke:#276749,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#header-fields-explained","title":"Header Fields Explained","text":"Offset Size Field Type Description 0x00 4 Magic char[4] ASCII string <code>GGUF</code> (0x47475546) - identifies file format 0x04 4 Version uint32_t Format version (currently 3) 0x08 8 Tensor Count uint64_t Number of tensors stored in the file 0x10 8 Metadata KV Count uint64_t Number of metadata key-value pairs"},{"location":"LLM/gguf-file-structure-guide/#version-history","title":"Version History","text":"<pre><code>timeline\n    title GGUF Version Evolution\n    section v1\n        Initial Release : Basic structure\n    section v2  \n        Alignment : Added padding for memory mapping\n    section v3\n        Current : Big-endian support, improved compatibility</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#section-2-metadata-key-value-pairs","title":"Section 2: Metadata Key-Value Pairs","text":"<p>Immediately following the header, metadata is stored as a sequence of key-value pairs. This section contains all model configuration, architecture details, tokenizer data, and custom attributes.</p>"},{"location":"LLM/gguf-file-structure-guide/#metadata-structure-overview","title":"Metadata Structure Overview","text":"<pre><code>flowchart TB\n    subgraph META[\"METADATA SECTION\"]\n        direction TB\n        KV1[\"Key-Value Pair 1\"]\n        KV2[\"Key-Value Pair 2\"]\n        KV3[\"Key-Value Pair 3\"]\n        KVN[\"Key-Value Pair N...\"]\n    end\n\n    subgraph KVPAIR[\"SINGLE KV PAIR STRUCTURE\"]\n        direction LR\n        KL[\"Key Length&lt;br/&gt;uint64\"]\n        KS[\"Key String&lt;br/&gt;UTF-8\"]\n        VT[\"Value Type&lt;br/&gt;uint32\"]\n        VD[\"Value Data&lt;br/&gt;variable\"]\n    end\n\n    KV1 --&gt; KV2 --&gt; KV3 --&gt; KVN\n\n    style KL fill:#4299e1,stroke:#2b6cb0,color:#fff\n    style KS fill:#48bb78,stroke:#2f855a,color:#fff\n    style VT fill:#ed8936,stroke:#c05621,color:#fff\n    style VD fill:#9f7aea,stroke:#6b46c1,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#value-types","title":"Value Types","text":"<p>GGUF supports multiple data types for metadata values:</p> <pre><code>flowchart TB\n    subgraph TYPES[\"GGUF VALUE TYPES\"]\n        direction TB\n\n        subgraph SCALAR[\"SCALAR TYPES\"]\n            T0[\"0: UINT8\"]\n            T1[\"1: INT8\"]\n            T2[\"2: UINT16\"]\n            T3[\"3: INT16\"]\n            T4[\"4: UINT32\"]\n            T5[\"5: INT32\"]\n            T6[\"6: FLOAT32\"]\n            T7[\"7: BOOL\"]\n            T10[\"10: UINT64\"]\n            T11[\"11: INT64\"]\n            T12[\"12: FLOAT64\"]\n        end\n\n        subgraph COMPLEX[\"COMPLEX TYPES\"]\n            T8[\"8: STRING&lt;br/&gt;length + UTF-8 data\"]\n            T9[\"9: ARRAY&lt;br/&gt;type + count + elements\"]\n        end\n    end\n\n    style T8 fill:#48bb78,stroke:#2f855a,color:#fff\n    style T9 fill:#ed8936,stroke:#c05621,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#type-id-reference-table","title":"Type ID Reference Table","text":"Type ID Name Size Description 0 UINT8 1 byte Unsigned 8-bit integer 1 INT8 1 byte Signed 8-bit integer 2 UINT16 2 bytes Unsigned 16-bit integer 3 INT16 2 bytes Signed 16-bit integer 4 UINT32 4 bytes Unsigned 32-bit integer 5 INT32 4 bytes Signed 32-bit integer 6 FLOAT32 4 bytes 32-bit floating point 7 BOOL 1 byte Boolean (0 or 1) 8 STRING variable Length-prefixed UTF-8 string 9 ARRAY variable Homogeneous typed array 10 UINT64 8 bytes Unsigned 64-bit integer 11 INT64 8 bytes Signed 64-bit integer 12 FLOAT64 8 bytes 64-bit floating point"},{"location":"LLM/gguf-file-structure-guide/#common-metadata-keys","title":"Common Metadata Keys","text":"<pre><code>mindmap\n  root((Metadata&lt;br/&gt;Keys))\n    General\n      general.architecture\n      general.name\n      general.author\n      general.license\n      general.quantization_version\n    Architecture\n      llama.context_length\n      llama.embedding_length\n      llama.block_count\n      llama.attention.head_count\n      llama.attention.head_count_kv\n      llama.rope.freq_base\n    Tokenizer\n      tokenizer.ggml.model\n      tokenizer.ggml.tokens\n      tokenizer.ggml.scores\n      tokenizer.ggml.token_type\n      tokenizer.ggml.bos_token_id\n      tokenizer.ggml.eos_token_id</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#string-encoding-detail","title":"String Encoding Detail","text":"<pre><code>flowchart LR\n    subgraph STRING[\"STRING VALUE ENCODING\"]\n        direction LR\n        SL[\"String Length&lt;br/&gt;uint64&lt;br/&gt;8 bytes\"]\n        SD[\"String Data&lt;br/&gt;UTF-8 bytes&lt;br/&gt;N bytes\"]\n    end\n\n    SL --&gt; SD\n\n    style SL fill:#4299e1,stroke:#2b6cb0,color:#fff\n    style SD fill:#48bb78,stroke:#2f855a,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#array-encoding-detail","title":"Array Encoding Detail","text":"<pre><code>flowchart LR\n    subgraph ARRAY[\"ARRAY VALUE ENCODING\"]\n        direction LR\n        AT[\"Element Type&lt;br/&gt;uint32&lt;br/&gt;4 bytes\"]\n        AC[\"Array Count&lt;br/&gt;uint64&lt;br/&gt;8 bytes\"]\n        AE[\"Elements&lt;br/&gt;type \u00d7 count&lt;br/&gt;variable\"]\n    end\n\n    AT --&gt; AC --&gt; AE\n\n    style AT fill:#ed8936,stroke:#c05621,color:#fff\n    style AC fill:#4299e1,stroke:#2b6cb0,color:#fff\n    style AE fill:#9f7aea,stroke:#6b46c1,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#section-3-tensor-information","title":"Section 3: Tensor Information","text":"<p>After metadata, the file contains descriptors for each tensor. These descriptors define tensor names, shapes, data types, and offsets into the data section.</p>"},{"location":"LLM/gguf-file-structure-guide/#tensor-info-structure","title":"Tensor Info Structure","text":"<pre><code>flowchart TB\n    subgraph TENSORS[\"TENSOR INFO SECTION\"]\n        direction TB\n        T1[\"Tensor Info 1\"]\n        T2[\"Tensor Info 2\"]\n        T3[\"Tensor Info 3\"]\n        TN[\"Tensor Info N...\"]\n    end\n\n    subgraph TINFO[\"SINGLE TENSOR INFO\"]\n        direction LR\n        NL[\"Name Length&lt;br/&gt;uint64\"]\n        NS[\"Name String&lt;br/&gt;UTF-8\"]\n        ND[\"N Dimensions&lt;br/&gt;uint32\"]\n        DM[\"Dimensions&lt;br/&gt;uint64 \u00d7 N\"]\n        TT[\"Tensor Type&lt;br/&gt;uint32\"]\n        OF[\"Data Offset&lt;br/&gt;uint64\"]\n    end\n\n    T1 --&gt; T2 --&gt; T3 --&gt; TN\n\n    style NL fill:#4299e1,stroke:#2b6cb0,color:#fff\n    style NS fill:#48bb78,stroke:#2f855a,color:#fff\n    style ND fill:#ed8936,stroke:#c05621,color:#fff\n    style DM fill:#f6e05e,stroke:#d69e2e,color:#333\n    style TT fill:#fc8181,stroke:#c53030,color:#fff\n    style OF fill:#9f7aea,stroke:#6b46c1,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#tensor-info-fields","title":"Tensor Info Fields","text":"Field Type Description Name Length uint64_t Length of tensor name in bytes Name char[] UTF-8 encoded tensor name N Dimensions uint32_t Number of dimensions (1-4 typically) Dimensions uint64_t[] Size of each dimension Type uint32_t Quantization/data type ID Offset uint64_t Byte offset from start of tensor data section"},{"location":"LLM/gguf-file-structure-guide/#tensorquantization-types","title":"Tensor/Quantization Types","text":"<pre><code>flowchart TB\n    subgraph QTYPES[\"TENSOR DATA TYPES\"]\n        direction LR\n\n        subgraph FULL[\"FULL PRECISION\"]\n            F32[\"F32&lt;br/&gt;32-bit float\"]\n            F16[\"F16&lt;br/&gt;16-bit float\"]\n            BF16[\"BF16&lt;br/&gt;bfloat16\"]\n        end\n\n        subgraph LEGACY[\"LEGACY QUANT\"]\n            Q4_0[\"Q4_0&lt;br/&gt;4-bit (32 block)\"]\n            Q4_1[\"Q4_1&lt;br/&gt;4-bit + min\"]\n            Q5_0[\"Q5_0&lt;br/&gt;5-bit\"]\n            Q5_1[\"Q5_1&lt;br/&gt;5-bit + min\"]\n            Q8_0[\"Q8_0&lt;br/&gt;8-bit\"]\n        end\n\n        subgraph KQUANT[\"K-QUANTS\"]\n            Q2_K[\"Q2_K&lt;br/&gt;2-bit k-quant\"]\n            Q3_K[\"Q3_K&lt;br/&gt;3-bit k-quant\"]\n            Q4_K[\"Q4_K&lt;br/&gt;4-bit k-quant\"]\n            Q5_K[\"Q5_K&lt;br/&gt;5-bit k-quant\"]\n            Q6_K[\"Q6_K&lt;br/&gt;6-bit k-quant\"]\n        end\n\n        subgraph IQUANT[\"I-QUANTS\"]\n            IQ2[\"IQ2_*&lt;br/&gt;2-bit importance\"]\n            IQ3[\"IQ3_*&lt;br/&gt;3-bit importance\"]\n            IQ4[\"IQ4_*&lt;br/&gt;4-bit importance\"]\n        end\n    end\n\n    style F32 fill:#48bb78,stroke:#2f855a,color:#fff\n    style F16 fill:#4299e1,stroke:#2b6cb0,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#quantization-type-ids","title":"Quantization Type IDs","text":"ID Type Bits/Weight Block Size Description 0 F32 32 1 Full 32-bit float 1 F16 16 1 Half precision float 2 Q4_0 4 32 4-bit quantization 3 Q4_1 4.5 32 4-bit with min value 6 Q5_0 5 32 5-bit quantization 7 Q5_1 5.5 32 5-bit with min value 8 Q8_0 8 32 8-bit quantization 10 Q2_K 2.5 256 K-quant 2-bit 11 Q3_K 3.4 256 K-quant 3-bit 12 Q4_K 4.5 256 K-quant 4-bit 13 Q5_K 5.5 256 K-quant 5-bit 14 Q6_K 6.5 256 K-quant 6-bit 30 BF16 16 1 Brain float 16"},{"location":"LLM/gguf-file-structure-guide/#section-4-tensor-data","title":"Section 4: Tensor Data","text":"<p>The final and largest section contains the actual tensor weights. Data is aligned for efficient memory-mapped access.</p>"},{"location":"LLM/gguf-file-structure-guide/#alignment-and-padding","title":"Alignment and Padding","text":"<pre><code>flowchart TB\n    subgraph ALIGN[\"DATA ALIGNMENT\"]\n        direction TB\n\n        END_META[\"End of Tensor Info Section\"]\n        PAD[\"ALIGNMENT PADDING&lt;br/&gt;Padded to 32-byte boundary\"]\n        DATA[\"TENSOR DATA START&lt;br/&gt;Aligned address\"]\n\n        END_META --&gt; PAD --&gt; DATA\n    end\n\n    subgraph LAYOUT[\"TENSOR DATA LAYOUT\"]\n        direction LR\n        T1D[\"Tensor 1 Data\"]\n        T2D[\"Tensor 2 Data\"]\n        T3D[\"Tensor 3 Data\"]\n        TND[\"Tensor N Data...\"]\n    end\n\n    DATA --&gt; LAYOUT\n    T1D --&gt; T2D --&gt; T3D --&gt; TND\n\n    style PAD fill:#fc8181,stroke:#c53030,color:#fff\n    style DATA fill:#48bb78,stroke:#2f855a,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#data-section-properties","title":"Data Section Properties","text":"<ul> <li>Alignment: Data starts at a 32-byte aligned offset (configurable, default 32)</li> <li>Tensor Order: Tensors are stored in the order their info appears</li> <li>No Padding Between Tensors: Tensors are packed contiguously (type-specific alignment may apply)</li> <li>Offsets: Each tensor's offset is relative to the start of the data section</li> </ul>"},{"location":"LLM/gguf-file-structure-guide/#complete-file-layout","title":"Complete File Layout","text":"<pre><code>flowchart TB\n    subgraph FILE[\"COMPLETE GGUF FILE BYTE LAYOUT\"]\n        direction TB\n\n        subgraph H[\"BYTES 0-23: HEADER\"]\n            H1[\"0x00-0x03: Magic 'GGUF'\"]\n            H2[\"0x04-0x07: Version\"]\n            H3[\"0x08-0x0F: Tensor Count\"]\n            H4[\"0x10-0x17: KV Count\"]\n        end\n\n        subgraph M[\"VARIABLE: METADATA\"]\n            M1[\"KV Pair 1\"]\n            M2[\"KV Pair 2\"]\n            M3[\"...\"]\n            MN[\"KV Pair N\"]\n        end\n\n        subgraph T[\"VARIABLE: TENSOR INFOS\"]\n            T1[\"Tensor Info 1\"]\n            T2[\"Tensor Info 2\"]\n            T3[\"...\"]\n            TN[\"Tensor Info N\"]\n        end\n\n        subgraph P[\"PADDING\"]\n            P1[\"Alignment Padding&lt;br/&gt;to 32-byte boundary\"]\n        end\n\n        subgraph D[\"BULK: TENSOR DATA\"]\n            D1[\"Tensor 1 Weights\"]\n            D2[\"Tensor 2 Weights\"]\n            D3[\"...\"]\n            DN[\"Tensor N Weights\"]\n        end\n    end\n\n    H --&gt; M --&gt; T --&gt; P --&gt; D\n\n    style H fill:#4a90d9,stroke:#2c5282,color:#fff\n    style M fill:#48bb78,stroke:#276749,color:#fff\n    style T fill:#ed8936,stroke:#c05621,color:#fff\n    style P fill:#a0aec0,stroke:#718096,color:#fff\n    style D fill:#9f7aea,stroke:#6b46c1,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#memory-mapping","title":"Memory Mapping","text":"<p>GGUF is designed for efficient memory-mapped loading:</p> <pre><code>flowchart LR\n    subgraph DISK[\"DISK FILE\"]\n        DF[\"GGUF File\"]\n    end\n\n    subgraph MMAP[\"MEMORY MAP\"]\n        VM[\"Virtual Memory&lt;br/&gt;Pages\"]\n    end\n\n    subgraph RAM[\"PHYSICAL RAM\"]\n        PM[\"Loaded Pages&lt;br/&gt;On Demand\"]\n    end\n\n    DF --&gt;|\"mmap()\"| VM\n    VM --&gt;|\"Page Fault\"| PM\n\n    style DF fill:#4299e1,stroke:#2b6cb0,color:#fff\n    style VM fill:#ed8936,stroke:#c05621,color:#fff\n    style PM fill:#48bb78,stroke:#2f855a,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#benefits-of-memory-mapping","title":"Benefits of Memory Mapping","text":"<ol> <li>Fast Load Times: Only metadata is read initially</li> <li>On-Demand Loading: Tensor pages loaded only when accessed</li> <li>Shared Memory: Multiple processes can share the same mapped file</li> <li>Low Memory Overhead: No need to copy data from disk buffer</li> </ol>"},{"location":"LLM/gguf-file-structure-guide/#typical-model-architecture-in-gguf","title":"Typical Model Architecture in GGUF","text":"<pre><code>flowchart TB\n    subgraph MODEL[\"TRANSFORMER MODEL TENSORS\"]\n        direction TB\n\n        subgraph EMB[\"EMBEDDINGS\"]\n            TE[\"token_embd.weight\"]\n        end\n\n        subgraph BLOCKS[\"TRANSFORMER BLOCKS \u00d7 N\"]\n            subgraph ATTN[\"ATTENTION\"]\n                QW[\"blk.N.attn_q.weight\"]\n                KW[\"blk.N.attn_k.weight\"]\n                VW[\"blk.N.attn_v.weight\"]\n                OW[\"blk.N.attn_output.weight\"]\n            end\n\n            subgraph FFN[\"FEED FORWARD\"]\n                G[\"blk.N.ffn_gate.weight\"]\n                U[\"blk.N.ffn_up.weight\"]\n                D[\"blk.N.ffn_down.weight\"]\n            end\n\n            subgraph NORM[\"LAYER NORMS\"]\n                AN[\"blk.N.attn_norm.weight\"]\n                FN[\"blk.N.ffn_norm.weight\"]\n            end\n        end\n\n        subgraph OUT[\"OUTPUT\"]\n            ON[\"output_norm.weight\"]\n            OL[\"output.weight\"]\n        end\n    end\n\n    EMB --&gt; BLOCKS --&gt; OUT\n\n    style TE fill:#4299e1,stroke:#2b6cb0,color:#fff\n    style OL fill:#48bb78,stroke:#2f855a,color:#fff</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#reading-gguf-in-python","title":"Reading GGUF in Python","text":"<p>Here's a minimal example for reading GGUF headers on Windows (CPU only):</p> <pre><code>import struct\n\ndef read_gguf_header(filepath):\n    \"\"\"Read GGUF file header information.\"\"\"\n    with open(filepath, 'rb') as f:\n        # Read magic\n        magic = f.read(4)\n        if magic != b'GGUF':\n            raise ValueError(f\"Invalid GGUF magic: {magic}\")\n\n        # Read version (uint32, little-endian)\n        version = struct.unpack('&lt;I', f.read(4))[0]\n\n        # Read tensor count (uint64, little-endian)\n        tensor_count = struct.unpack('&lt;Q', f.read(8))[0]\n\n        # Read metadata kv count (uint64, little-endian)\n        metadata_kv_count = struct.unpack('&lt;Q', f.read(8))[0]\n\n        return {\n            'magic': magic.decode('ascii'),\n            'version': version,\n            'tensor_count': tensor_count,\n            'metadata_kv_count': metadata_kv_count\n        }\n\n# Usage\n# header = read_gguf_header(\"model.gguf\")\n# print(header)\n</code></pre>"},{"location":"LLM/gguf-file-structure-guide/#tools-for-working-with-gguf","title":"Tools for Working with GGUF","text":"Tool Purpose Platform <code>llama.cpp</code> Inference engine Windows/Linux/Mac <code>gguf-py</code> Python GGUF library Cross-platform <code>llama-quantize</code> Quantization tool Windows/Linux/Mac <code>llama-gguf</code> GGUF manipulation Windows/Linux/Mac"},{"location":"LLM/gguf-file-structure-guide/#summary","title":"Summary","text":"<pre><code>flowchart TB\n    subgraph SUMMARY[\"GGUF FORMAT SUMMARY\"]\n        direction LR\n\n        S1[\"\ud83d\udd12 Self-Contained&lt;br/&gt;Single file distribution\"]\n        S2[\"\u26a1 Memory Mapped&lt;br/&gt;Fast loading\"]\n        S3[\"\ud83d\udcca Quantized&lt;br/&gt;Reduced size\"]\n        S4[\"\ud83d\udccb Metadata Rich&lt;br/&gt;Complete model info\"]\n    end\n\n    style S1 fill:#4299e1,stroke:#2b6cb0,color:#fff\n    style S2 fill:#48bb78,stroke:#2f855a,color:#fff\n    style S3 fill:#ed8936,stroke:#c05621,color:#fff\n    style S4 fill:#9f7aea,stroke:#6b46c1,color:#fff</code></pre> <p>Key Takeaways:</p> <ol> <li>Header (24 bytes): Magic number, version, counts</li> <li>Metadata: Key-value pairs for model configuration and tokenizer</li> <li>Tensor Info: Names, dimensions, types, and offsets for each tensor</li> <li>Tensor Data: Aligned, quantized weight data</li> </ol> <p>GGUF enables efficient distribution and inference of large language models on consumer hardware, including CPU-only systems like your Lenovo Yoga with 32GB RAM.</p> <p>Guide generated for GGUF format version 3</p>"},{"location":"LLM/safetensors_file_structure/","title":"Safetensors File Format Structure","text":"<p>The <code>.safetensors</code> format is a simple, fast, and safe file format created by Hugging Face for storing tensors. It was designed to address security vulnerabilities in pickle-based formats (like PyTorch's <code>.pt</code> files) while being extremely fast to load.</p>"},{"location":"LLM/safetensors_file_structure/#high-level-structure","title":"High-Level Structure","text":"<p>A safetensors file consists of exactly three sequential regions:</p> <pre><code>graph LR\n    subgraph \"Safetensors File Layout\"\n        A[\"Header Size&lt;br/&gt;(8 bytes)\"] --&gt; B[\"JSON Header&lt;br/&gt;(variable size)\"]\n        B --&gt; C[\"Tensor Data&lt;br/&gt;(raw bytes)\"]\n    end\n\n    style A fill:#e74c3c,color:#fff\n    style B fill:#3498db,color:#fff\n    style C fill:#27ae60,color:#fff</code></pre>"},{"location":"LLM/safetensors_file_structure/#1-header-size-bytes-07","title":"1. Header Size (Bytes 0\u20137)","text":"<p>The first 8 bytes store a little-endian unsigned 64-bit integer indicating the size of the JSON header in bytes.</p> <pre><code>graph TB\n    subgraph \"Header Size Field (8 bytes)\"\n        direction LR\n        B0[\"Byte 0&lt;br/&gt;LSB\"] --- B1[\"Byte 1\"] --- B2[\"Byte 2\"] --- B3[\"Byte 3\"] --- B4[\"Byte 4\"] --- B5[\"Byte 5\"] --- B6[\"Byte 6\"] --- B7[\"Byte 7&lt;br/&gt;MSB\"]\n    end\n\n    Note[\"Example: If header is 256 bytes&lt;br/&gt;Stored as: 0x00 0x01 0x00 0x00 0x00 0x00 0x00 0x00\"]\n\n    style B0 fill:#e74c3c,color:#fff\n    style B7 fill:#e74c3c,color:#fff</code></pre> <p>Key Points: - Little-endian byte order (least significant byte first) - Maximum theoretical header size: 2^64 bytes (practically limited by file system) - This fixed-size prefix enables fast header parsing</p>"},{"location":"LLM/safetensors_file_structure/#2-json-header-bytes-8-to-8n","title":"2. JSON Header (Bytes 8 to 8+N)","text":"<p>The header is a UTF-8 encoded JSON object containing metadata for all tensors and optional file-level metadata.</p> <pre><code>graph TB\n    subgraph \"JSON Header Structure\"\n        ROOT[\"{ }\"]\n        ROOT --&gt; META[\"__metadata__&lt;br/&gt;(optional)\"]\n        ROOT --&gt; T1[\"tensor_name_1\"]\n        ROOT --&gt; T2[\"tensor_name_2\"]\n        ROOT --&gt; TN[\"...more tensors\"]\n\n        META --&gt; M1[\"key: value pairs&lt;br/&gt;(all strings)\"]\n\n        T1 --&gt; D1[\"dtype\"]\n        T1 --&gt; S1[\"shape\"]\n        T1 --&gt; O1[\"data_offsets\"]\n\n        D1 --&gt; DV1[\"'F32' | 'F16' | 'BF16' | 'I32' | ...\"]\n        S1 --&gt; SV1[\"[dim0, dim1, ...]\"]\n        O1 --&gt; OV1[\"[start, end]\"]\n    end\n\n    style ROOT fill:#3498db,color:#fff\n    style META fill:#9b59b6,color:#fff\n    style T1 fill:#f39c12,color:#fff\n    style T2 fill:#f39c12,color:#fff\n    style TN fill:#f39c12,color:#fff</code></pre>"},{"location":"LLM/safetensors_file_structure/#tensor-entry-fields","title":"Tensor Entry Fields","text":"Field Type Description <code>dtype</code> string Data type of tensor elements <code>shape</code> array of integers Dimensions of the tensor <code>data_offsets</code> [start, end] Byte range in data region (exclusive end)"},{"location":"LLM/safetensors_file_structure/#header-json-example","title":"Header JSON Example","text":"<pre><code>{\n  \"__metadata__\": {\n    \"format\": \"pt\",\n    \"author\": \"huggingface\",\n    \"description\": \"Example model weights\"\n  },\n  \"model.embed.weight\": {\n    \"dtype\": \"F16\",\n    \"shape\": [50257, 768],\n    \"data_offsets\": [0, 77194752]\n  },\n  \"model.layer.0.attn.weight\": {\n    \"dtype\": \"F16\",\n    \"shape\": [768, 768],\n    \"data_offsets\": [77194752, 78373888]\n  },\n  \"model.layer.0.attn.bias\": {\n    \"dtype\": \"F16\",\n    \"shape\": [768],\n    \"data_offsets\": [78373888, 78375424]\n  }\n}\n</code></pre>"},{"location":"LLM/safetensors_file_structure/#the-__metadata__-section","title":"The <code>__metadata__</code> Section","text":"<ul> <li>Optional section for arbitrary file-level metadata</li> <li>All values must be strings (not numbers or objects)</li> <li>Common uses: format version, author, training info, license</li> </ul>"},{"location":"LLM/safetensors_file_structure/#3-tensor-data-region-bytes-8n-onwards","title":"3. Tensor Data Region (Bytes 8+N onwards)","text":"<p>Raw tensor bytes stored contiguously. Each tensor's location is defined by <code>data_offsets</code> relative to the start of the data region (not the file).</p> <pre><code>graph TB\n    subgraph \"Data Region Layout\"\n        direction LR\n        T1[\"Tensor 1&lt;br/&gt;bytes [0, end1)\"]\n        T2[\"Tensor 2&lt;br/&gt;bytes [end1, end2)\"]\n        T3[\"Tensor 3&lt;br/&gt;bytes [end2, end3)\"]\n        TN[\"...\"]\n\n        T1 --&gt; T2 --&gt; T3 --&gt; TN\n    end\n\n    subgraph \"Offset Mapping\"\n        O1[\"data_offsets: [0, 1024]\"] -.-&gt; T1\n        O2[\"data_offsets: [1024, 5120]\"] -.-&gt; T2\n        O3[\"data_offsets: [5120, 9216]\"] -.-&gt; T3\n    end\n\n    style T1 fill:#27ae60,color:#fff\n    style T2 fill:#27ae60,color:#fff\n    style T3 fill:#27ae60,color:#fff</code></pre>"},{"location":"LLM/safetensors_file_structure/#calculating-tensor-size","title":"Calculating Tensor Size","text":"<p>The size of each tensor in bytes can be calculated as:</p> <pre><code>tensor_size = data_offsets[1] - data_offsets[0]\n</code></pre> <p>Or verified via shape and dtype:</p> <pre><code>tensor_size = product(shape) \u00d7 bytes_per_element(dtype)\n</code></pre>"},{"location":"LLM/safetensors_file_structure/#complete-file-layout-with-byte-addresses","title":"Complete File Layout with Byte Addresses","text":"<pre><code>graph TB\n    subgraph \"Complete Safetensors File\"\n        direction TB\n\n        subgraph \"Address 0x0000\"\n            HS[\"HEADER SIZE&lt;br/&gt;8 bytes, uint64 LE&lt;br/&gt;Value: N\"]\n        end\n\n        subgraph \"Address 0x0008\"\n            HD[\"JSON HEADER&lt;br/&gt;N bytes, UTF-8&lt;br/&gt;Tensor metadata + optional __metadata__\"]\n        end\n\n        subgraph \"Address 0x0008 + N\"\n            DATA[\"TENSOR DATA REGION&lt;br/&gt;Raw bytes, contiguous&lt;br/&gt;Offsets are relative to this point\"]\n        end\n    end\n\n    HS --&gt; HD --&gt; DATA\n\n    style HS fill:#e74c3c,color:#fff\n    style HD fill:#3498db,color:#fff\n    style DATA fill:#27ae60,color:#fff</code></pre>"},{"location":"LLM/safetensors_file_structure/#address-calculation-formula","title":"Address Calculation Formula","text":"<p>To find the absolute file position of a tensor:</p> <pre><code>absolute_position = 8 + header_size + data_offsets[0]\n</code></pre>"},{"location":"LLM/safetensors_file_structure/#supported-data-types","title":"Supported Data Types","text":"dtype String Description Bytes per Element NumPy Equivalent <code>F64</code> 64-bit float 8 <code>float64</code> <code>F32</code> 32-bit float 4 <code>float32</code> <code>F16</code> 16-bit float 2 <code>float16</code> <code>BF16</code> Brain float 16 2 N/A (use <code>bfloat16</code>) <code>I64</code> 64-bit signed int 8 <code>int64</code> <code>I32</code> 32-bit signed int 4 <code>int32</code> <code>I16</code> 16-bit signed int 2 <code>int16</code> <code>I8</code> 8-bit signed int 1 <code>int8</code> <code>U8</code> 8-bit unsigned int 1 <code>uint8</code> <code>BOOL</code> Boolean 1 <code>bool</code>"},{"location":"LLM/safetensors_file_structure/#memory-mapping-advantage","title":"Memory Mapping Advantage","text":"<pre><code>flowchart LR\n    subgraph \"Traditional Loading\"\n        A1[Read File] --&gt; A2[Parse All] --&gt; A3[Allocate RAM] --&gt; A4[Copy to RAM]\n    end\n\n    subgraph \"Safetensors Memory Mapping\"\n        B1[Open File] --&gt; B2[Parse Header Only] --&gt; B3[mmap Data Region] --&gt; B4[Access on Demand]\n    end\n\n    A4 --&gt; SLOW[\"\u274c Slow, High RAM\"]\n    B4 --&gt; FAST[\"\u2705 Fast, Low RAM\"]\n\n    style SLOW fill:#e74c3c,color:#fff\n    style FAST fill:#27ae60,color:#fff</code></pre>"},{"location":"LLM/safetensors_file_structure/#why-memory-mapping-works","title":"Why Memory Mapping Works","text":"<p>The key design benefit: since offsets point directly into contiguous raw data, the entire data region can be memory-mapped. </p> <p>Benefits include: - Fast startup: Only header is parsed initially - Lazy loading: Tensor bytes loaded only when accessed - Shared memory: Multiple processes can share the same mapped region - Reduced RAM: OS manages page swapping automatically</p>"},{"location":"LLM/safetensors_file_structure/#why-its-safe","title":"Why It's \"Safe\"","text":"<pre><code>graph TB\n    subgraph \"Security Comparison\"\n        direction LR\n\n        subgraph \"Pickle (.pt, .pkl)\"\n            P1[\"Arbitrary Python Code\"] --&gt; P2[\"Can Execute on Load\"] --&gt; P3[\"\ud83d\udd34 Remote Code Execution Risk\"]\n        end\n\n        subgraph \"Safetensors\"\n            S1[\"JSON + Raw Bytes Only\"] --&gt; S2[\"No Code Execution\"] --&gt; S3[\"\ud83d\udfe2 Safe to Load\"]\n        end\n    end\n\n    style P3 fill:#e74c3c,color:#fff\n    style S3 fill:#27ae60,color:#fff</code></pre>"},{"location":"LLM/safetensors_file_structure/#security-features","title":"Security Features","text":"<ol> <li>No code execution: Contains only JSON and raw numeric data</li> <li>Bounded reads: Header size prevents buffer overflow attacks</li> <li>Validation: Offsets can be verified before accessing data</li> <li>Deterministic parsing: No deserialization of arbitrary objects</li> </ol>"},{"location":"LLM/safetensors_file_structure/#summary-table","title":"Summary Table","text":"Region Start Address Size Content Header Size <code>0x0000</code> 8 bytes Little-endian uint64 JSON Header <code>0x0008</code> N bytes (from header size) UTF-8 JSON with tensor metadata Tensor Data <code>0x0008 + N</code> Remaining file Raw contiguous tensor bytes"},{"location":"LLM/safetensors_file_structure/#reading-a-safetensors-file-pseudocode","title":"Reading a Safetensors File (Pseudocode)","text":"<pre><code>def read_safetensors(filepath):\n    with open(filepath, 'rb') as f:\n        # 1. Read header size (first 8 bytes)\n        header_size = int.from_bytes(f.read(8), byteorder='little')\n\n        # 2. Read and parse JSON header\n        header_json = f.read(header_size).decode('utf-8')\n        header = json.loads(header_json)\n\n        # 3. Data region starts at offset 8 + header_size\n        data_start = 8 + header_size\n\n        # 4. Load specific tensor\n        tensor_info = header['model.embed.weight']\n        start, end = tensor_info['data_offsets']\n\n        f.seek(data_start + start)\n        raw_bytes = f.read(end - start)\n\n        # 5. Convert to numpy array\n        dtype_map = {'F32': np.float32, 'F16': np.float16, ...}\n        array = np.frombuffer(raw_bytes, dtype=dtype_map[tensor_info['dtype']])\n        array = array.reshape(tensor_info['shape'])\n\n        return array\n</code></pre>"},{"location":"LLM/safetensors_file_structure/#references","title":"References","text":"<ul> <li>Hugging Face Safetensors Repository</li> <li>Safetensors Documentation</li> </ul>"},{"location":"LLM/transformer-weights-explained/","title":"Transformer Weights Explained: What They Actually Are","text":""},{"location":"LLM/transformer-weights-explained/#common-misconception","title":"Common Misconception","text":"<p>A common misconception is that weights represent the \"value of a path from one token to another.\" This is incorrect.</p> <p>Weights are learned numerical parameters stored in matrices (tensors). They don't represent direct \"paths between tokens\" \u2014 instead, they define transformations that the model applies to convert inputs into outputs through many layers.</p> <pre><code>Weights \u2260 \"Token A \u2192 Token B = 0.7\"\n\nWeights = Matrices that transform vectors through mathematical operations\n</code></pre>"},{"location":"LLM/transformer-weights-explained/#how-tokens-actually-flow-through-the-model","title":"How Tokens Actually Flow Through the Model","text":"<pre><code>flowchart TB\n    subgraph INPUT[\"INPUT\"]\n        T1[\"Token: 'Hello'\"]\n        T2[\"Token: 'world'\"]\n    end\n\n    subgraph EMB[\"EMBEDDING LAYER\"]\n        E1[\"Vector: [0.12, -0.45, 0.89, ...]&lt;br/&gt;4096 dimensions\"]\n        E2[\"Vector: [0.34, 0.21, -0.56, ...]&lt;br/&gt;4096 dimensions\"]\n    end\n\n    subgraph TRANSFORM[\"TRANSFORMER LAYERS \u00d7 N\"]\n        ATT[\"Attention&lt;br/&gt;(weights transform queries, keys, values)\"]\n        FFN[\"Feed-Forward Network&lt;br/&gt;(weights transform representations)\"]\n    end\n\n    subgraph OUTPUT[\"OUTPUT\"]\n        LOGITS[\"Logits: probability scores&lt;br/&gt;for ALL vocab tokens\"]\n        NEXT[\"Next token: '!'&lt;br/&gt;(highest probability)\"]\n    end\n\n    T1 --&gt; E1\n    T2 --&gt; E2\n    E1 &amp; E2 --&gt; ATT --&gt; FFN --&gt; LOGITS --&gt; NEXT\n\n    style EMB fill:#4a90d9,stroke:#2c5282,color:#fff\n    style TRANSFORM fill:#48bb78,stroke:#276749,color:#fff\n    style LOGITS fill:#ed8936,stroke:#c05621,color:#fff</code></pre>"},{"location":"LLM/transformer-weights-explained/#the-key-weight-tensors-in-a-transformer","title":"The Key Weight Tensors in a Transformer","text":"<p>Each tensor serves a specific mathematical purpose:</p>"},{"location":"LLM/transformer-weights-explained/#1-token-embeddings-token_embdweight","title":"1. Token Embeddings (<code>token_embd.weight</code>)","text":"<pre><code>Shape: [vocab_size \u00d7 embedding_dim]\nExample: [32000 \u00d7 4096]\n</code></pre> <ul> <li>Maps each token ID to a dense vector</li> <li>Token 1547 (\"Hello\") \u2192 look up row 1547 \u2192 get 4096-dimensional vector</li> <li>This is a lookup table, not a path</li> </ul>"},{"location":"LLM/transformer-weights-explained/#2-attention-weights-per-layer","title":"2. Attention Weights (per layer)","text":"<pre><code>Q weight: [hidden_dim \u00d7 hidden_dim]  \u2014 transforms input to \"Query\"\nK weight: [hidden_dim \u00d7 hidden_dim]  \u2014 transforms input to \"Key\"  \nV weight: [hidden_dim \u00d7 hidden_dim]  \u2014 transforms input to \"Value\"\nO weight: [hidden_dim \u00d7 hidden_dim]  \u2014 projects attention output\n</code></pre> <ul> <li>These matrices learn what to pay attention to</li> <li>Attention scores between tokens are computed at runtime, not stored</li> </ul>"},{"location":"LLM/transformer-weights-explained/#3-feed-forward-weights-per-layer","title":"3. Feed-Forward Weights (per layer)","text":"<pre><code>ffn_up:   [hidden_dim \u00d7 intermediate_dim]\nffn_down: [intermediate_dim \u00d7 hidden_dim]\nffn_gate: [hidden_dim \u00d7 intermediate_dim]  (for gated architectures)\n</code></pre> <ul> <li>Transform the representation through a non-linear \"thinking\" step</li> </ul>"},{"location":"LLM/transformer-weights-explained/#4-output-layer-outputweight","title":"4. Output Layer (<code>output.weight</code>)","text":"<pre><code>Shape: [embedding_dim \u00d7 vocab_size]\nExample: [4096 \u00d7 32000]\n</code></pre> <ul> <li>Converts final hidden state \u2192 scores for every possible next token</li> </ul>"},{"location":"LLM/transformer-weights-explained/#analogy-weights-as-lenses","title":"Analogy: Weights as \"Lenses\"","text":"<pre><code>flowchart LR\n    subgraph WRONG[\"\u274c WRONG MENTAL MODEL\"]\n        A1[Token A] --&gt;|\"weight = 0.7\"| B1[Token B]\n        A1 --&gt;|\"weight = 0.2\"| C1[Token C]\n    end\n\n    subgraph RIGHT[\"\u2705 CORRECT MENTAL MODEL\"]\n        IN[\"Input Vector&lt;br/&gt;[0.1, 0.5, -0.3, ...]\"]\n        W[\"Weight Matrix&lt;br/&gt;(learned lens)\"]\n        OUT[\"Output Vector&lt;br/&gt;[0.8, -0.2, 0.4, ...]\"]\n        IN --&gt;|\"matrix multiply\"| W --&gt;|\"produces\"| OUT\n    end</code></pre> <p>Weights are like lenses that transform the meaning of input vectors. The model learns during training how to shape these lenses so that, after many transformations, the final output correctly predicts the next token.</p>"},{"location":"LLM/transformer-weights-explained/#what-the-tokentoken-model-might-be-confused-with","title":"What the \"Token\u2192Token\" Model Might Be Confused With","text":"Concept What It Is N-gram models Older models that did store direct token\u2192token probabilities Attention scores Computed at runtime (not stored) \u2014 how much each token attends to others Graph neural networks Where edge weights connect nodes directly <p>In transformers, the \"relationship\" between tokens is computed dynamically through matrix operations using the stored weights \u2014 it's not pre-stored as a lookup table.</p>"},{"location":"LLM/transformer-weights-explained/#matrix-multiplication-the-core-operation","title":"Matrix Multiplication: The Core Operation","text":"<p>Every layer applies weights through matrix multiplication:</p> <pre><code>flowchart LR\n    subgraph MATMUL[\"MATRIX MULTIPLICATION\"]\n        INPUT[\"Input Vector&lt;br/&gt;[1 \u00d7 4096]\"]\n        WEIGHT[\"Weight Matrix&lt;br/&gt;[4096 \u00d7 4096]\"]\n        OUTPUT[\"Output Vector&lt;br/&gt;[1 \u00d7 4096]\"]\n\n        INPUT --&gt; WEIGHT --&gt; OUTPUT\n    end</code></pre> <p>Mathematical form:</p> <pre><code>output = input \u00d7 weight_matrix + bias\n</code></pre> <p>Each element in the output is a weighted sum of all input elements. The weights determine how to combine the input values.</p>"},{"location":"LLM/transformer-weights-explained/#example-a-single-attention-head","title":"Example: A Single Attention Head","text":"<pre><code>flowchart TB\n    subgraph ATTENTION[\"SINGLE ATTENTION HEAD\"]\n        direction TB\n\n        X[\"Input X&lt;br/&gt;(sequence of vectors)\"]\n\n        subgraph PROJ[\"PROJECTIONS (using stored weights)\"]\n            Q[\"Q = X \u00d7 W_q\"]\n            K[\"K = X \u00d7 W_k\"]\n            V[\"V = X \u00d7 W_v\"]\n        end\n\n        SCORES[\"Attention Scores&lt;br/&gt;softmax(Q \u00d7 K^T / \u221ad)&lt;br/&gt;&lt;em&gt;computed at runtime&lt;/em&gt;\"]\n\n        OUT[\"Output = Scores \u00d7 V\"]\n    end\n\n    X --&gt; Q &amp; K &amp; V\n    Q &amp; K --&gt; SCORES\n    SCORES &amp; V --&gt; OUT\n\n    style PROJ fill:#4a90d9,stroke:#2c5282,color:#fff\n    style SCORES fill:#ed8936,stroke:#c05621,color:#fff</code></pre> <p>Key insight: The weights (<code>W_q</code>, <code>W_k</code>, <code>W_v</code>) are stored, but the attention scores (which tokens attend to which) are computed fresh for every input.</p>"},{"location":"LLM/transformer-weights-explained/#stored-vs-computed","title":"Stored vs. Computed","text":"Stored in GGUF Weights Computed at Runtime Weight matrices (parameters) Token-to-token attention scores Token embeddings (lookup table) Attention patterns Layer normalization values Intermediate activations Bias terms Probability distributions"},{"location":"LLM/transformer-weights-explained/#why-quantization-works","title":"Why Quantization Works","text":"<p>Since weights are just numbers in matrices, we can compress them:</p> Precision Bits per Weight Memory for 7B Model FP32 32 bits ~28 GB FP16 16 bits ~14 GB Q8_0 8 bits ~7 GB Q4_K ~4.5 bits ~4 GB Q2_K ~2.5 bits ~2.5 GB <p>Quantization trades precision for size. The model still performs the same operations, just with less precise numbers.</p>"},{"location":"LLM/transformer-weights-explained/#summary","title":"Summary","text":"<p>The magic of LLMs is that billions of weight values, when combined through matrix multiplications across many layers, produce emergent behavior that appears to understand token relationships \u2014 but those relationships are computed, not stored.</p> <pre><code>flowchart TB\n    subgraph SUMMARY[\"KEY TAKEAWAY\"]\n        W[\"Billions of Weights&lt;br/&gt;(stored parameters)\"]\n        M[\"Matrix Operations&lt;br/&gt;(at runtime)\"]\n        E[\"Emergent Understanding&lt;br/&gt;(appears intelligent)\"]\n\n        W --&gt;|\"combined through\"| M --&gt;|\"produces\"| E\n    end\n\n    style W fill:#9f7aea,stroke:#6b46c1,color:#fff\n    style M fill:#ed8936,stroke:#c05621,color:#fff\n    style E fill:#48bb78,stroke:#276749,color:#fff</code></pre> <p>Guide created to clarify transformer weight mechanics</p>"},{"location":"LLM/why_models_have_multiple_tensors/","title":"Why AI Models Consist of Multiple Tensors","text":"<p>This document explains why a <code>.safetensors</code> file representing an AI model is composed of many distinct tensors rather than one giant tensor.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#the-core-reason-neural-networks-are-graphs-of-operations","title":"The Core Reason: Neural Networks Are Graphs of Operations","text":"<p>A neural network isn't a single mathematical operation\u2014it's a directed graph of many distinct operations, each with its own learned parameters.</p> <pre><code>graph LR\n    subgraph \"Simple Neural Network\"\n        I[Input] --&gt; L1[\"Layer 1&lt;br/&gt;weights + bias\"]\n        L1 --&gt; A1[Activation]\n        A1 --&gt; L2[\"Layer 2&lt;br/&gt;weights + bias\"]\n        L2 --&gt; A2[Activation]\n        A2 --&gt; L3[\"Layer 3&lt;br/&gt;weights + bias\"]\n        L3 --&gt; O[Output]\n    end\n\n    style L1 fill:#3498db,color:#fff\n    style L2 fill:#3498db,color:#fff\n    style L3 fill:#3498db,color:#fff</code></pre> <p>Each blue box represents separate tensors with different shapes and purposes.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#reason-1-different-shapes-for-different-operations","title":"Reason 1: Different Shapes for Different Operations","text":"<p>Each layer performs a specific mathematical operation requiring a specific tensor shape.</p> <pre><code>graph TB\n    subgraph \"Transformer Block - Different Tensor Shapes\"\n        EMB[\"Embedding&lt;br/&gt;[vocab_size \u00d7 hidden_dim]&lt;br/&gt;50257 \u00d7 768\"]\n\n        QKV[\"Q, K, V Projections&lt;br/&gt;[hidden \u00d7 hidden] each&lt;br/&gt;768 \u00d7 768\"]\n\n        ATT_OUT[\"Attention Output&lt;br/&gt;[hidden \u00d7 hidden]&lt;br/&gt;768 \u00d7 768\"]\n\n        FFN1[\"FFN Layer 1&lt;br/&gt;[hidden \u00d7 4\u00d7hidden]&lt;br/&gt;768 \u00d7 3072\"]\n\n        FFN2[\"FFN Layer 2&lt;br/&gt;[4\u00d7hidden \u00d7 hidden]&lt;br/&gt;3072 \u00d7 768\"]\n\n        LN[\"Layer Norm&lt;br/&gt;[hidden]&lt;br/&gt;768\"]\n    end\n\n    EMB --&gt; QKV --&gt; ATT_OUT --&gt; FFN1 --&gt; FFN2\n    LN -.-&gt; |\"Applied at multiple points\"| QKV\n\n    style EMB fill:#e74c3c,color:#fff\n    style QKV fill:#3498db,color:#fff\n    style FFN1 fill:#27ae60,color:#fff\n    style FFN2 fill:#27ae60,color:#fff\n    style LN fill:#9b59b6,color:#fff</code></pre> <p>You cannot combine a [50257 \u00d7 768] tensor with a [768 \u00d7 768] tensor into one\u2014they have incompatible shapes and serve different purposes.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#reason-2-weights-vs-biases","title":"Reason 2: Weights vs. Biases","text":"<p>Even within a single layer, weights and biases are separate tensors:</p> <pre><code>graph LR\n    subgraph \"Single Linear Layer: y = Wx + b\"\n        X[\"Input x&lt;br/&gt;[batch, 768]\"]\n        W[\"Weight W&lt;br/&gt;[768, 768]&lt;br/&gt;2D tensor\"]\n        B[\"Bias b&lt;br/&gt;[768]&lt;br/&gt;1D tensor\"]\n        Y[\"Output y&lt;br/&gt;[batch, 768]\"]\n\n        X --&gt; |\"matrix multiply\"| MUL[\"\u00d7\"]\n        W --&gt; MUL\n        MUL --&gt; ADD[\"+\"]\n        B --&gt; ADD\n        ADD --&gt; Y\n    end\n\n    style W fill:#3498db,color:#fff\n    style B fill:#e74c3c,color:#fff</code></pre> <p>The weight is a 2D matrix, the bias is a 1D vector. Different shapes = different tensors.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#reason-3-modularity-and-flexibility","title":"Reason 3: Modularity and Flexibility","text":"<p>Separate tensors enable:</p> Capability How Separate Tensors Help Fine-tuning Freeze some layers, train others Transfer learning Replace just the final layer LoRA adapters Add small tensors alongside existing ones Pruning Remove individual layers or heads Quantization Apply different precision to different layers Inspection Analyze specific layer behaviors <pre><code>graph TB\n    subgraph \"Fine-Tuning Example\"\n        direction TB\n        FROZEN[\"Frozen Layers&lt;br/&gt;(loaded, not trained)\"]\n        TRAINABLE[\"New Classification Head&lt;br/&gt;(randomly initialized, trained)\"]\n\n        FROZEN --&gt; TRAINABLE\n    end\n\n    style FROZEN fill:#95a5a6,color:#fff\n    style TRAINABLE fill:#27ae60,color:#fff</code></pre> <p>If everything were one tensor, you couldn't selectively freeze or modify parts.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#reason-4-memory-efficiency-during-computation","title":"Reason 4: Memory Efficiency During Computation","text":"<p>During inference, not all tensors are needed simultaneously:</p> <pre><code>sequenceDiagram\n    participant RAM as System RAM\n    participant GPU as GPU Memory\n    participant Compute as Computation\n\n    Note over RAM: All tensors stored\n\n    RAM-&gt;&gt;GPU: Load Layer 1 weights\n    GPU-&gt;&gt;Compute: Process Layer 1\n    GPU--&gt;&gt;RAM: Optionally offload\n\n    RAM-&gt;&gt;GPU: Load Layer 2 weights\n    GPU-&gt;&gt;Compute: Process Layer 2\n    GPU--&gt;&gt;RAM: Optionally offload\n\n    Note over GPU: Only active layer&lt;br/&gt;needs GPU memory</code></pre> <p>Separate tensors allow layer-by-layer streaming for models larger than GPU memory.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#reason-5-a-real-models-tensor-inventory","title":"Reason 5: A Real Model's Tensor Inventory","text":"<p>A typical transformer model contains these tensor categories:</p> <pre><code>graph TB\n    subgraph \"GPT-2 Style Model Tensors\"\n        subgraph \"Embeddings\"\n            WTE[\"wte.weight&lt;br/&gt;Token embeddings&lt;br/&gt;[50257, 768]\"]\n            WPE[\"wpe.weight&lt;br/&gt;Position embeddings&lt;br/&gt;[1024, 768]\"]\n        end\n\n        subgraph \"Per-Layer Tensors (\u00d712 layers)\"\n            LN1[\"ln_1.weight, ln_1.bias&lt;br/&gt;[768] each\"]\n            ATT[\"attn.c_attn.weight&lt;br/&gt;[768, 2304]\"]\n            ATTB[\"attn.c_attn.bias&lt;br/&gt;[2304]\"]\n            PROJ[\"attn.c_proj.weight&lt;br/&gt;[768, 768]\"]\n            LN2[\"ln_2.weight, ln_2.bias&lt;br/&gt;[768] each\"]\n            MLP1[\"mlp.c_fc.weight&lt;br/&gt;[768, 3072]\"]\n            MLP2[\"mlp.c_proj.weight&lt;br/&gt;[3072, 768]\"]\n        end\n\n        subgraph \"Final\"\n            LNF[\"ln_f.weight, ln_f.bias&lt;br/&gt;[768] each\"]\n        end\n    end\n\n    style WTE fill:#e74c3c,color:#fff\n    style WPE fill:#e74c3c,color:#fff\n    style ATT fill:#3498db,color:#fff\n    style MLP1 fill:#27ae60,color:#fff\n    style MLP2 fill:#27ae60,color:#fff</code></pre> <p>GPT-2 Small has 148 separate tensors. GPT-2 XL has 292 tensors. LLaMA 70B has thousands.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#why-not-flatten-everything-into-one-tensor","title":"Why Not Flatten Everything Into One Tensor?","text":"<p>You could technically concatenate all parameters into a single 1D tensor:</p> <pre><code>graph LR\n    subgraph \"Hypothetical Single Tensor\"\n        FLAT[\"[param_0, param_1, param_2, ..., param_N]&lt;br/&gt;One giant 1D array\"]\n    end\n\n    subgraph \"Problems\"\n        P1[\"\u274c Lose shape information\"]\n        P2[\"\u274c Can't do matrix operations directly\"]\n        P3[\"\u274c Must reshape constantly\"]\n        P4[\"\u274c Can't load partially\"]\n        P5[\"\u274c Can't apply different dtypes\"]\n    end\n\n    FLAT --&gt; P1\n    FLAT --&gt; P2\n    FLAT --&gt; P3\n    FLAT --&gt; P4\n    FLAT --&gt; P5\n\n    style FLAT fill:#e74c3c,color:#fff</code></pre> <p>You'd need a separate metadata structure to track where each layer's parameters begin and end, what shape to reshape them into, etc.\u2014essentially recreating what safetensors already does, but less efficiently.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#the-mathematical-perspective","title":"The Mathematical Perspective","text":"<p>A neural network computes a function by composing many smaller functions:</p> <pre><code>output = f_n( f_{n-1}( ... f_2( f_1( input ) ) ... ) )\n</code></pre> <p>Each function <code>f_i</code> typically has the form:</p> <pre><code>f_i(x) = activation( W_i \u00b7 x + b_i )\n</code></pre> <p>Where: - <code>W_i</code> is a weight matrix (2D tensor) - <code>b_i</code> is a bias vector (1D tensor) - Each layer has its own <code>W</code> and <code>b</code></p> <p>This mathematical structure inherently requires multiple separate parameter tensors.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#analogy-a-car-vs-its-parts","title":"Analogy: A Car vs. Its Parts","text":"<p>Think of asking \"why does a car have multiple parts instead of one?\"</p> <pre><code>graph TB\n    subgraph \"A Car's Components\"\n        ENGINE[\"Engine&lt;br/&gt;(converts fuel to motion)\"]\n        TRANS[\"Transmission&lt;br/&gt;(transfers power)\"]\n        WHEELS[\"Wheels&lt;br/&gt;(contact ground)\"]\n        STEERING[\"Steering&lt;br/&gt;(direction control)\"]\n        BRAKES[\"Brakes&lt;br/&gt;(stopping)\"]\n    end\n\n    ENGINE --&gt; TRANS --&gt; WHEELS\n    STEERING --&gt; WHEELS\n    BRAKES --&gt; WHEELS\n\n    style ENGINE fill:#e74c3c,color:#fff\n    style TRANS fill:#3498db,color:#fff\n    style WHEELS fill:#27ae60,color:#fff</code></pre> <p>Each component: - Has a different shape (you can't combine an engine and a wheel) - Serves a different function - Can be replaced independently - Must be connected in a specific way</p> <p>Neural network tensors are the same\u2014each serves a specific purpose in the computation.</p>"},{"location":"LLM/why_models_have_multiple_tensors/#summary","title":"Summary","text":"Reason Explanation Mathematical necessity Different operations require different tensor shapes Architectural structure Networks are graphs of distinct operations Weights vs. biases Even one layer has multiple parameter tensors Modularity Enables fine-tuning, pruning, quantization Memory management Allows streaming and partial loading Framework design PyTorch/TensorFlow organize models as named parameter collections"},{"location":"LLM/why_models_have_multiple_tensors/#conclusion","title":"Conclusion","text":"<p>The multiple-tensor design directly mirrors the mathematical structure of neural networks. Each tensor represents a learnable parameter matrix or vector for a specific operation in the computation graph.</p> <p>A single-tensor design would: 1. Lose the natural correspondence between tensors and operations 2. Require constant reshaping during computation 3. Prevent partial loading and fine-tuning 4. Make the model file format more complex, not simpler</p> <p>The safetensors format (and all model formats) use multiple named tensors because that's what neural networks fundamentally are: collections of distinct, shaped parameter arrays connected in a computation graph.</p>"},{"location":"Markdown/mermaidjs-complete-guide/","title":"MermaidJS Complete Diagram Guide","text":"<p>Mermaid is a JavaScript-based diagramming and charting tool that uses text definitions to create diagrams dynamically. This guide covers every diagram type and element available in MermaidJS.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Flowchart</li> <li>Sequence Diagram</li> <li>Class Diagram</li> <li>State Diagram</li> <li>Entity Relationship Diagram</li> <li>User Journey</li> <li>Gantt Chart</li> <li>Pie Chart</li> <li>Quadrant Chart</li> <li>Requirement Diagram</li> <li>Gitgraph Diagram</li> <li>Mindmap</li> <li>Timeline</li> <li>Sankey Diagram</li> <li>XY Chart</li> <li>Block Diagram</li> <li>Packet Diagram</li> <li>Architecture Diagram</li> <li>Kanban Board</li> </ol>"},{"location":"Markdown/mermaidjs-complete-guide/#1-flowchart","title":"1. Flowchart","text":"<p>Flowcharts are composed of nodes and edges. They support various shapes, link styles, and directions.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#directions","title":"Directions","text":"<ul> <li><code>TB</code> / <code>TD</code> - Top to Bottom</li> <li><code>BT</code> - Bottom to Top</li> <li><code>LR</code> - Left to Right</li> <li><code>RL</code> - Right to Left</li> </ul>"},{"location":"Markdown/mermaidjs-complete-guide/#node-shapes","title":"Node Shapes","text":"<pre><code>flowchart LR\n    A[Rectangle] --&gt; B(Rounded Rectangle)\n    B --&gt; C([Stadium])\n    C --&gt; D[[Subroutine]]\n    D --&gt; E[(Database)]\n    E --&gt; F((Circle))</code></pre> <pre><code>flowchart LR\n    G&gt;Asymmetric] --&gt; H{Diamond}\n    H --&gt; I{{Hexagon}}\n    I --&gt; J[/Parallelogram/]\n    J --&gt; K[\\Parallelogram Alt\\]\n    K --&gt; L[/Trapezoid\\]</code></pre> <pre><code>flowchart LR\n    M[\\Trapezoid Alt/] --&gt; N(((Double Circle)))</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#linkedge-types","title":"Link/Edge Types","text":"<pre><code>flowchart LR\n    A --&gt; B\n    A --- C\n    A -.- D\n    A -.-&gt; E\n    A ==&gt; F\n    A ~~~ G\n\n    H -- text --&gt; I\n    J -. text .-&gt; K\n    L == text ==&gt; M</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#link-length","title":"Link Length","text":"<pre><code>flowchart TD\n    A ---&gt; B\n    A ----&gt; C\n    A -----&gt; D</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#subgraphs","title":"Subgraphs","text":"<pre><code>flowchart TB\n    subgraph one [First Subgraph]\n        A1 --&gt; A2\n    end\n    subgraph two [Second Subgraph]\n        B1 --&gt; B2\n    end\n    subgraph three [Third Subgraph]\n        C1 --&gt; C2\n    end\n    one --&gt; two\n    three --&gt; two\n    two --&gt; C2</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#styling","title":"Styling","text":"<pre><code>flowchart LR\n    A:::someclass --&gt; B\n    classDef someclass fill:#f96,stroke:#333,stroke-width:2px\n\n    C --&gt; D\n    style D fill:#bbf,stroke:#f66,stroke-width:2px,color:#fff,stroke-dasharray: 5 5</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#complete-flowchart-example","title":"Complete Flowchart Example","text":"<pre><code>flowchart TD\n    Start([Start]) --&gt; Input[/Get User Input/]\n    Input --&gt; Validate{Is Valid?}\n    Validate --&gt;|Yes| Process[Process Data]\n    Validate --&gt;|No| Error[Show Error]\n    Error --&gt; Input\n    Process --&gt; Database[(Save to DB)]\n    Database --&gt; Output[\\Display Results\\]\n    Output --&gt; End([End])\n\n    style Start fill:#9f9,stroke:#333\n    style End fill:#f99,stroke:#333</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#2-sequence-diagram","title":"2. Sequence Diagram","text":"<p>Sequence diagrams show how processes interact with each other and in what order.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#participants-and-actors","title":"Participants and Actors","text":"<pre><code>sequenceDiagram\n    participant A as Alice\n    actor B as Bob\n    participant C as Charlie\n\n    A-&gt;&gt;B: Hello Bob!\n    B-&gt;&gt;C: Hi Charlie!\n    C-&gt;&gt;A: Hey Alice!</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#message-types","title":"Message Types","text":"<pre><code>sequenceDiagram\n    participant A\n    participant B\n\n    A-&gt;B: Solid line without arrow\n    A--&gt;B: Dotted line without arrow\n    A-&gt;&gt;B: Solid line with arrowhead\n    A--&gt;&gt;B: Dotted line with arrowhead\n    A-xB: Solid line with cross\n    A--xB: Dotted line with cross\n    A-)B: Solid line with open arrow (async)\n    A--)B: Dotted line with open arrow (async)</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#activations","title":"Activations","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Server\n\n    Client-&gt;&gt;+Server: Request\n    Server-&gt;&gt;+Server: Process\n    Server--&gt;&gt;-Server: Done\n    Server--&gt;&gt;-Client: Response</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#notes","title":"Notes","text":"<pre><code>sequenceDiagram\n    participant A\n    participant B\n\n    Note left of A: Note on left\n    Note right of B: Note on right\n    Note over A: Note over A\n    Note over A,B: Note spanning both\n\n    A-&gt;&gt;B: Message</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#loops-alt-opt-par-critical-break","title":"Loops, Alt, Opt, Par, Critical, Break","text":"<pre><code>sequenceDiagram\n    participant User\n    participant System\n\n    User-&gt;&gt;System: Login Request\n\n    alt Valid Credentials\n        System-&gt;&gt;User: Login Success\n    else Invalid Credentials\n        System-&gt;&gt;User: Login Failed\n    end\n\n    opt Remember Me\n        System-&gt;&gt;System: Store Session\n    end\n\n    loop Health Check\n        System-&gt;&gt;System: Check Status\n    end\n\n    par Parallel Task A\n        System-&gt;&gt;System: Task A\n    and Parallel Task B\n        System-&gt;&gt;System: Task B\n    end\n\n    critical Establish Connection\n        System-&gt;&gt;System: Connect\n    option Connection Timeout\n        System-&gt;&gt;User: Retry\n    end\n\n    break Something Went Wrong\n        System-&gt;&gt;User: Error Response\n    end</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#boxes-grouping","title":"Boxes (Grouping)","text":"<pre><code>sequenceDiagram\n    box Purple Client Side\n        participant Browser\n        participant App\n    end\n    box Green Server Side\n        participant API\n        participant Database\n    end\n\n    Browser-&gt;&gt;App: User Action\n    App-&gt;&gt;API: API Request\n    API-&gt;&gt;Database: Query\n    Database--&gt;&gt;API: Results\n    API--&gt;&gt;App: Response\n    App--&gt;&gt;Browser: Update UI</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#autonumbering","title":"Autonumbering","text":"<pre><code>sequenceDiagram\n    autonumber\n    Alice-&gt;&gt;John: Hello John\n    John--&gt;&gt;Alice: Hi Alice\n    Alice-&gt;&gt;John: How are you?\n    John--&gt;&gt;Alice: I'm good!</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#3-class-diagram","title":"3. Class Diagram","text":"<p>Class diagrams are used in object-oriented modeling to describe the structure of a system.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#basic-class-definition","title":"Basic Class Definition","text":"<pre><code>classDiagram\n    class Animal {\n        +String name\n        +int age\n        +makeSound() void\n        +move() void\n    }</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#visibility-modifiers","title":"Visibility Modifiers","text":"<pre><code>classDiagram\n    class Example {\n        +publicAttribute\n        -privateAttribute\n        #protectedAttribute\n        ~packageAttribute\n        +publicMethod()\n        -privateMethod()\n        #protectedMethod()\n        ~packageMethod()\n    }</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#relationships","title":"Relationships","text":"<pre><code>classDiagram\n    classA &lt;|-- classB : Inheritance\n    classC *-- classD : Composition\n    classE o-- classF : Aggregation\n    classG &lt;-- classH : Association\n    classI -- classJ : Link (Solid)\n    classK &lt;.. classL : Dependency\n    classM &lt;|.. classN : Realization\n    classO .. classP : Link (Dashed)</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#cardinality","title":"Cardinality","text":"<pre><code>classDiagram\n    Customer \"1\" --&gt; \"*\" Order : places\n    Order \"1\" --&gt; \"1..*\" LineItem : contains\n    Product \"1\" --&gt; \"0..*\" LineItem : appears in</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#class-annotations","title":"Class Annotations","text":"<pre><code>classDiagram\n    class Shape {\n        &lt;&lt;interface&gt;&gt;\n        +draw()\n        +area() double\n    }\n\n    class AbstractShape {\n        &lt;&lt;abstract&gt;&gt;\n        #color: String\n        +getColor() String\n    }\n\n    class ShapeService {\n        &lt;&lt;service&gt;&gt;\n        +createShape() Shape\n    }\n\n    class ShapeType {\n        &lt;&lt;enumeration&gt;&gt;\n        CIRCLE\n        SQUARE\n        TRIANGLE\n    }</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#complete-example","title":"Complete Example","text":"<pre><code>classDiagram\n    class Animal {\n        &lt;&lt;abstract&gt;&gt;\n        +String name\n        +int age\n        +makeSound()* void\n        +move() void\n    }\n\n    class Dog {\n        +String breed\n        +makeSound() void\n        +fetch() void\n    }\n\n    class Cat {\n        +boolean indoor\n        +makeSound() void\n        +scratch() void\n    }\n\n    class Pet {\n        &lt;&lt;interface&gt;&gt;\n        +play() void\n        +feed() void\n    }\n\n    Animal &lt;|-- Dog\n    Animal &lt;|-- Cat\n    Pet &lt;|.. Dog\n    Pet &lt;|.. Cat</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#namespaces","title":"Namespaces","text":"<pre><code>classDiagram\n    namespace Animals {\n        class Dog\n        class Cat\n    }\n    namespace Vehicles {\n        class Car\n        class Bike\n    }</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#4-state-diagram","title":"4. State Diagram","text":"<p>State diagrams describe the behavior of a system, showing states and transitions.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#basic-states","title":"Basic States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Idle\n    Idle --&gt; Processing : Start\n    Processing --&gt; Completed : Finish\n    Completed --&gt; [*]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#composite-states","title":"Composite States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Active\n\n    state Active {\n        [*] --&gt; Idle\n        Idle --&gt; Running : start\n        Running --&gt; Idle : stop\n        Running --&gt; Running : process\n    }\n\n    Active --&gt; Inactive : deactivate\n    Inactive --&gt; Active : activate\n    Inactive --&gt; [*]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#fork-and-join","title":"Fork and Join","text":"<pre><code>stateDiagram-v2\n    state fork_state &lt;&lt;fork&gt;&gt;\n    state join_state &lt;&lt;join&gt;&gt;\n\n    [*] --&gt; fork_state\n    fork_state --&gt; State1\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    State1 --&gt; join_state\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n\n    join_state --&gt; FinalState\n    FinalState --&gt; [*]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#choice","title":"Choice","text":"<pre><code>stateDiagram-v2\n    state check_result &lt;&lt;choice&gt;&gt;\n\n    [*] --&gt; Processing\n    Processing --&gt; check_result\n    check_result --&gt; Success : if valid\n    check_result --&gt; Failure : if invalid\n    Success --&gt; [*]\n    Failure --&gt; [*]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#notes_1","title":"Notes","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Active\n    Active --&gt; Inactive\n\n    note right of Active\n        This is an active state\n        It can process events\n    end note\n\n    note left of Inactive : This is inactive</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#concurrency","title":"Concurrency","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Active\n\n    state Active {\n        [*] --&gt; ProcessA\n        --\n        [*] --&gt; ProcessB\n        --\n        [*] --&gt; ProcessC\n    }\n\n    Active --&gt; [*]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#direction","title":"Direction","text":"<pre><code>stateDiagram-v2\n    direction LR\n    [*] --&gt; A\n    A --&gt; B\n    B --&gt; C\n    C --&gt; [*]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#5-entity-relationship-diagram","title":"5. Entity Relationship Diagram","text":"<p>ER diagrams show relationships between entities in a database.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#relationship-types","title":"Relationship Types","text":"<pre><code>erDiagram\n    CUSTOMER ||--o{ ORDER : places\n    ORDER ||--|{ LINE-ITEM : contains\n    CUSTOMER }|..|{ DELIVERY-ADDRESS : uses\n    PRODUCT ||--o{ LINE-ITEM : \"ordered in\"</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#cardinality-notation","title":"Cardinality Notation","text":"Value Meaning <code>\\|o</code> Zero or one <code>\\|\\|</code> Exactly one <code>}o</code> Zero or more <code>}\\|</code> One or more"},{"location":"Markdown/mermaidjs-complete-guide/#entity-attributes","title":"Entity Attributes","text":"<pre><code>erDiagram\n    CUSTOMER {\n        int id PK\n        string name\n        string email UK\n        date created_at\n    }\n\n    ORDER {\n        int id PK\n        int customer_id FK\n        date order_date\n        decimal total\n    }\n\n    PRODUCT {\n        int id PK\n        string name\n        decimal price\n        string description\n    }\n\n    LINE_ITEM {\n        int id PK\n        int order_id FK\n        int product_id FK\n        int quantity\n    }\n\n    CUSTOMER ||--o{ ORDER : places\n    ORDER ||--|{ LINE_ITEM : contains\n    PRODUCT ||--o{ LINE_ITEM : included_in</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#attribute-types","title":"Attribute Types","text":"<pre><code>erDiagram\n    ENTITY {\n        type attribute_name PK \"Primary Key\"\n        type attribute_name FK \"Foreign Key\"\n        type attribute_name UK \"Unique Key\"\n    }</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#6-user-journey","title":"6. User Journey","text":"<p>User journey diagrams describe the steps a user takes to complete a task.</p> <pre><code>journey\n    title My Working Day\n    section Morning\n        Wake up: 1: Me\n        Breakfast: 3: Me\n        Commute: 2: Me, Bus\n    section Work\n        Check emails: 3: Me\n        Meeting: 2: Me, Colleagues\n        Lunch: 5: Me\n        Coding: 4: Me\n    section Evening\n        Commute home: 2: Me, Bus\n        Dinner: 5: Me, Family\n        Sleep: 5: Me</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#score-values","title":"Score Values","text":"<p>Scores range from 1 to 5: - 1: Very negative experience - 2: Negative experience - 3: Neutral experience - 4: Positive experience - 5: Very positive experience</p>"},{"location":"Markdown/mermaidjs-complete-guide/#7-gantt-chart","title":"7. Gantt Chart","text":"<p>Gantt charts illustrate project schedules.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#basic-gantt","title":"Basic Gantt","text":"<pre><code>gantt\n    title Project Timeline\n    dateFormat YYYY-MM-DD\n\n    section Planning\n        Requirements    :a1, 2024-01-01, 7d\n        Design          :a2, after a1, 5d\n\n    section Development\n        Backend         :b1, after a2, 14d\n        Frontend        :b2, after a2, 14d\n        Integration     :b3, after b1, 5d\n\n    section Testing\n        Unit Tests      :c1, after b3, 7d\n        QA Testing      :c2, after c1, 7d</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#task-types","title":"Task Types","text":"<pre><code>gantt\n    title Task Types Example\n    dateFormat YYYY-MM-DD\n\n    section Tasks\n        Normal task         :a1, 2024-01-01, 3d\n        Critical task       :crit, a2, after a1, 2d\n        Done task           :done, a3, after a2, 2d\n        Active task         :active, a4, after a3, 3d\n        Milestone           :milestone, m1, after a4, 0d</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#sections-and-dependencies","title":"Sections and Dependencies","text":"<pre><code>gantt\n    title Software Development Lifecycle\n    dateFormat YYYY-MM-DD\n    excludes weekends\n\n    section Analysis\n        Gather Requirements     :done, req, 2024-01-01, 5d\n        Analyze Requirements    :done, ana, after req, 3d\n\n    section Design\n        System Design           :active, des, after ana, 5d\n        UI/UX Design            :uix, after ana, 7d\n\n    section Implementation\n        Core Development        :dev, after des, 15d\n        API Development         :api, after des, 10d\n\n    section Testing\n        Testing                 :test, after dev, 10d\n\n    section Deployment\n        Deployment              :milestone, dep, after test, 0d</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#8-pie-chart","title":"8. Pie Chart","text":"<pre><code>pie showData\n    title Browser Market Share\n    \"Chrome\" : 65\n    \"Safari\" : 19\n    \"Firefox\" : 4\n    \"Edge\" : 4\n    \"Other\" : 8</code></pre> <pre><code>pie\n    title Project Budget Allocation\n    \"Development\" : 45\n    \"Marketing\" : 20\n    \"Operations\" : 15\n    \"Support\" : 12\n    \"R&amp;D\" : 8</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#9-quadrant-chart","title":"9. Quadrant Chart","text":"<p>Quadrant charts plot items on a 2x2 grid for prioritization or classification.</p> <pre><code>quadrantChart\n    title Product Feature Prioritization\n    x-axis Low Effort --&gt; High Effort\n    y-axis Low Impact --&gt; High Impact\n    quadrant-1 Plan\n    quadrant-2 Do First\n    quadrant-3 Delegate\n    quadrant-4 Eliminate\n\n    Feature A: [0.8, 0.9]\n    Feature B: [0.3, 0.8]\n    Feature C: [0.7, 0.3]\n    Feature D: [0.2, 0.2]\n    Feature E: [0.5, 0.5]\n    Feature F: [0.9, 0.7]</code></pre> <pre><code>quadrantChart\n    title Skill Assessment\n    x-axis Low Competence --&gt; High Competence\n    y-axis Low Interest --&gt; High Interest\n    quadrant-1 Develop\n    quadrant-2 Leverage\n    quadrant-3 Ignore\n    quadrant-4 Delegate\n\n    Python: [0.9, 0.8]\n    JavaScript: [0.7, 0.7]\n    Rust: [0.3, 0.9]\n    Java: [0.6, 0.3]\n    Go: [0.4, 0.6]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#10-requirement-diagram","title":"10. Requirement Diagram","text":"<p>Requirement diagrams show requirements and their relationships.</p> <pre><code>requirementDiagram\n    requirement user_auth {\n        id: REQ-001\n        text: The system shall authenticate users\n        risk: high\n        verifymethod: test\n    }\n\n    requirement password_policy {\n        id: REQ-002\n        text: Passwords must be at least 8 characters\n        risk: medium\n        verifymethod: inspection\n    }\n\n    requirement session_mgmt {\n        id: REQ-003\n        text: Sessions shall expire after 30 minutes\n        risk: low\n        verifymethod: demonstration\n    }\n\n    element auth_module {\n        type: module\n        docRef: auth_design_doc\n    }\n\n    element login_test {\n        type: testCase\n        docRef: test_plan_001\n    }\n\n    user_auth - derives -&gt; password_policy\n    user_auth - derives -&gt; session_mgmt\n    auth_module - satisfies -&gt; user_auth\n    login_test - verifies -&gt; user_auth</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#relationship-types_1","title":"Relationship Types","text":"<ul> <li><code>contains</code> - Requirement contains another requirement</li> <li><code>copies</code> - Requirement is a copy of another</li> <li><code>derives</code> - Requirement derives from another</li> <li><code>satisfies</code> - Element satisfies requirement</li> <li><code>verifies</code> - Element verifies requirement</li> <li><code>refines</code> - Requirement refines another</li> <li><code>traces</code> - Requirement traces to another</li> </ul>"},{"location":"Markdown/mermaidjs-complete-guide/#11-gitgraph-diagram","title":"11. Gitgraph Diagram","text":"<p>Gitgraph diagrams visualize git branching and merging.</p> <pre><code>gitGraph\n    commit id: \"Initial\"\n    commit id: \"Add README\"\n    branch develop\n    checkout develop\n    commit id: \"Setup project\"\n    commit id: \"Add core features\"\n    branch feature/auth\n    checkout feature/auth\n    commit id: \"Add login\"\n    commit id: \"Add logout\"\n    checkout develop\n    merge feature/auth\n    branch feature/dashboard\n    checkout feature/dashboard\n    commit id: \"Create dashboard\"\n    commit id: \"Add widgets\"\n    checkout develop\n    merge feature/dashboard\n    checkout main\n    merge develop tag: \"v1.0.0\"\n    commit id: \"Hotfix\"</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#customization-options","title":"Customization Options","text":"<pre><code>%%{init: { 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchName': 'production'}} }%%\ngitGraph\n    commit id: \"1\"\n    commit id: \"2\"\n    branch staging\n    checkout staging\n    commit id: \"3\"\n    checkout production\n    merge staging\n    commit id: \"4\"</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#cherry-pick","title":"Cherry-pick","text":"<pre><code>gitGraph\n    commit id: \"A\"\n    commit id: \"B\"\n    branch develop\n    commit id: \"C\"\n    commit id: \"D\"\n    checkout main\n    cherry-pick id: \"C\"\n    commit id: \"E\"</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#12-mindmap","title":"12. Mindmap","text":"<p>Mindmaps visualize hierarchical information.</p> <pre><code>mindmap\n    root((Project Planning))\n        Research\n            Market Analysis\n            Competitor Review\n            User Surveys\n        Design\n            Wireframes\n            Mockups\n            Prototypes\n        Development\n            Frontend\n                React\n                CSS\n                TypeScript\n            Backend\n                Node.js\n                Database\n                API\n        Testing\n            Unit Tests\n            Integration Tests\n            E2E Tests\n        Deployment\n            CI/CD\n            Monitoring\n            Scaling</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#node-shapes_1","title":"Node Shapes","text":"<pre><code>mindmap\n    root)Cloud Shape(\n        (Rounded Square)\n            [Square]\n                {{Hexagon}}\n        ))Bang((\n            Default Text</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#icons-and-classes","title":"Icons and Classes","text":"<pre><code>mindmap\n    root((Central Topic))\n        ::icon(fa fa-book)\n        Topic A\n            Subtopic A1\n            Subtopic A2\n        Topic B\n            ::icon(fa fa-code)\n            Subtopic B1\n        Topic C</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#13-timeline","title":"13. Timeline","text":"<p>Timeline diagrams show events over time.</p> <pre><code>timeline\n    title History of Web Development\n\n    section 1990s\n        1991 : First website created\n        1993 : HTML 1.0\n        1995 : JavaScript created\n             : PHP released\n        1996 : CSS 1.0\n        1998 : Google founded\n\n    section 2000s\n        2004 : Facebook launched\n        2005 : YouTube launched\n             : AJAX popularized\n        2006 : jQuery released\n        2008 : HTML5 draft\n\n    section 2010s\n        2010 : AngularJS\n        2013 : React released\n        2014 : Vue.js released\n        2015 : ES6/ES2015\n\n    section 2020s\n        2020 : Remote work boom\n        2022 : ChatGPT launched\n        2023 : AI integration</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#14-sankey-diagram","title":"14. Sankey Diagram","text":"<p>Sankey diagrams visualize flow quantities between nodes.</p> <pre><code>sankey-beta\n\n%% source, target, value\nElectricity,Residential,30\nElectricity,Commercial,25\nElectricity,Industrial,45\n\nNatural Gas,Residential,20\nNatural Gas,Commercial,15\nNatural Gas,Industrial,35\n\nCoal,Industrial,50\nCoal,Power Plants,100\n\nPower Plants,Electricity,100\n\nRenewable,Electricity,40</code></pre> <pre><code>sankey-beta\n\nBudget,Marketing,250\nBudget,Development,400\nBudget,Operations,200\nBudget,HR,150\n\nMarketing,Digital,150\nMarketing,Traditional,100\n\nDevelopment,Frontend,150\nDevelopment,Backend,150\nDevelopment,DevOps,100\n\nOperations,Infrastructure,100\nOperations,Support,100</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#15-xy-chart","title":"15. XY Chart","text":"<p>XY charts display data on a coordinate system.</p>"},{"location":"Markdown/mermaidjs-complete-guide/#bar-chart","title":"Bar Chart","text":"<pre><code>xychart-beta\n    title \"Monthly Sales\"\n    x-axis [Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec]\n    y-axis \"Revenue (in $1000)\" 0 --&gt; 150\n    bar [50, 60, 75, 90, 80, 95, 110, 120, 100, 85, 95, 130]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#line-chart","title":"Line Chart","text":"<pre><code>xychart-beta\n    title \"Temperature Trend\"\n    x-axis [Mon, Tue, Wed, Thu, Fri, Sat, Sun]\n    y-axis \"Temperature (\u00b0C)\" 0 --&gt; 40\n    line [22, 24, 26, 28, 25, 23, 21]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#combined-bar-and-line","title":"Combined Bar and Line","text":"<pre><code>xychart-beta\n    title \"Sales vs Target\"\n    x-axis [Q1, Q2, Q3, Q4]\n    y-axis \"Amount ($)\" 0 --&gt; 200\n    bar [120, 150, 140, 180]\n    line [100, 130, 160, 190]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#16-block-diagram","title":"16. Block Diagram","text":"<p>Block diagrams show system components and their relationships.</p> <pre><code>block-beta\n    columns 3\n\n    Frontend:3\n\n    space API space\n\n    block:backend:3\n        columns 3\n        Auth Database Cache\n    end\n\n    space Storage space</code></pre> <pre><code>block-beta\n    columns 5\n\n    User space:3 Admin\n\n    space down1&lt;[\"  \"]&gt;(down) space down2&lt;[\"  \"]&gt;(down) space\n\n    space WebApp:3 space\n\n    space down3&lt;[\"  \"]&gt;(down) space\n\n    space API:3 space\n\n    space down4&lt;[\"  \"]&gt;(down) space\n\n    DB[(\"Database\")]:5</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#block-shapes","title":"Block Shapes","text":"<pre><code>block-beta\n    A[\"Rectangle\"]\n    B(\"Rounded\")\n    C((\"Circle\"))\n    D{{\"Hexagon\"}}\n    E[/\"Parallelogram\"/]\n    F[\\\\\"Parallelogram Alt\"\\\\]\n    G[(\"Cylinder\")]\n    H&gt;\"Asymmetric\"]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#17-packet-diagram","title":"17. Packet Diagram","text":"<p>Packet diagrams show the structure of network packets.</p> <pre><code>packet-beta\n    0-15: \"Source Port\"\n    16-31: \"Destination Port\"\n    32-63: \"Sequence Number\"\n    64-95: \"Acknowledgment Number\"\n    96-99: \"Data Offset\"\n    100-102: \"Reserved\"\n    103: \"NS\"\n    104: \"CWR\"\n    105: \"ECE\"\n    106: \"URG\"\n    107: \"ACK\"\n    108: \"PSH\"\n    109: \"RST\"\n    110: \"SYN\"\n    111: \"FIN\"\n    112-127: \"Window Size\"\n    128-143: \"Checksum\"\n    144-159: \"Urgent Pointer\"\n    160-191: \"Options (if Data Offset &gt; 5)\"</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#18-architecture-diagram","title":"18. Architecture Diagram","text":"<p>Architecture diagrams show system architecture with cloud/infrastructure components.</p> <pre><code>architecture-beta\n    group cloud(cloud)[Cloud Platform]\n\n    service users(internet)[Users] in cloud\n    service lb(server)[Load Balancer] in cloud\n    service api(server)[API Server] in cloud\n    service db(database)[Database] in cloud\n\n    users:R --&gt; L:lb\n    lb:R --&gt; L:api\n    api:R --&gt; L:db</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#19-kanban-board","title":"19. Kanban Board","text":"<p>Kanban diagrams visualize work items across workflow stages.</p> <pre><code>kanban\n    column1[Todo]\n        task1[Design homepage]\n        task2[Write documentation]\n        task3[Create database schema]\n\n    column2[In Progress]\n        task4[Implement auth]\n        task5[Build API endpoints]\n\n    column3[Review]\n        task6[Code review: login]\n\n    column4[Done]\n        task7[Setup project]\n        task8[Configure CI/CD]</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#theming-and-configuration","title":"Theming and Configuration","text":""},{"location":"Markdown/mermaidjs-complete-guide/#built-in-themes","title":"Built-in Themes","text":"<p>Mermaid supports several built-in themes: - <code>default</code> - <code>neutral</code> - <code>dark</code> - <code>forest</code> - <code>base</code></p> <pre><code>%%{init: {'theme': 'forest'}}%%\nflowchart LR\n    A --&gt; B --&gt; C --&gt; D</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#custom-theme-variables","title":"Custom Theme Variables","text":"<pre><code>%%{init: {\n    'theme': 'base',\n    'themeVariables': {\n        'primaryColor': '#ff6b6b',\n        'primaryTextColor': '#fff',\n        'primaryBorderColor': '#c92a2a',\n        'lineColor': '#868e96',\n        'secondaryColor': '#ffd43b',\n        'tertiaryColor': '#e9ecef'\n    }\n}}%%\nflowchart LR\n    A[Start] --&gt; B{Decision}\n    B --&gt;|Yes| C[Action 1]\n    B --&gt;|No| D[Action 2]\n    C --&gt; E[End]\n    D --&gt; E</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#directives-and-comments","title":"Directives and Comments","text":""},{"location":"Markdown/mermaidjs-complete-guide/#comments","title":"Comments","text":"<pre><code>flowchart LR\n    %% This is a comment\n    A --&gt; B\n    %% Another comment\n    B --&gt; C</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#directives","title":"Directives","text":"<pre><code>%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%%\nflowchart LR\n    A --&gt; B</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#accessibility","title":"Accessibility","text":"<p>Mermaid supports accessibility descriptions:</p> <pre><code>flowchart LR\n    accTitle: Simple Flow\n    accDescr: A flow showing three connected nodes A, B, and C\n\n    A --&gt; B --&gt; C</code></pre>"},{"location":"Markdown/mermaidjs-complete-guide/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ol> <li>Keep diagrams simple: Complex diagrams become hard to read</li> <li>Use meaningful labels: Clear labels improve understanding</li> <li>Choose the right diagram type: Match the diagram to your data</li> <li>Use subgraphs for organization: Group related elements</li> <li>Apply consistent styling: Use themes or custom styles consistently</li> <li>Add titles and descriptions: Improve accessibility and context</li> <li>Test rendering: Different renderers may have slight variations</li> </ol>"},{"location":"Markdown/mermaidjs-complete-guide/#resources","title":"Resources","text":"<ul> <li>Mermaid Official Documentation</li> <li>Mermaid Live Editor</li> <li>GitHub Repository</li> </ul> <p>This guide covers MermaidJS version 10.x. Some features may vary in different versions.</p>"}]}